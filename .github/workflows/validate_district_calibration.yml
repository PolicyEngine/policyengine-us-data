name: Validate District-Level Calibration

on:
  push:
    branches:
      - new-cd-var
  workflow_dispatch:
    inputs:
      gcs_date:
        description: 'GCS date prefix (e.g., 2025-10-22-1721)'
        required: true
        type: string

jobs:
  validate-and-upload:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install dependencies
        run: uv pip install -e .[dev] --system

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: "projects/322898545428/locations/global/workloadIdentityPools/policyengine-research-id-pool/providers/prod-github-provider"
          service_account: "policyengine-research@policyengine-research.iam.gserviceaccount.com"

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Download weights from GCS
        run: |
          GCS_DATE="${{ inputs.gcs_date || '2025-10-22-1721' }}"
          echo "Downloading weights from gs://policyengine-calibration/$GCS_DATE/outputs/"
          mkdir -p policyengine_us_data/storage/calibration
          gsutil ls gs://policyengine-calibration/$GCS_DATE/outputs/**/w_cd.npy | head -1 | xargs -I {} gsutil cp {} policyengine_us_data/storage/calibration/w_cd.npy
          echo "Downloaded w_cd.npy"

      - name: Download prerequisite datasets
        run: |
          echo "Downloading stratified dataset and database..."
          gsutil -q stat gs://policyengine-us-data/stratified_extended_cps_2023.h5 && \
            gsutil cp gs://policyengine-us-data/stratified_extended_cps_2023.h5 policyengine_us_data/storage/ || \
            echo "Dataset already exists or download failed"
          gsutil -q stat gs://policyengine-us-data/policy_data.db && \
            gsutil cp gs://policyengine-us-data/policy_data.db policyengine_us_data/storage/ || \
            echo "Database already exists or download failed"

      - name: Create state files
        run: |
          echo "Creating state-level .h5 files..."
          python -m policyengine_us_data.datasets.cps.geo_stacking_calibration.create_sparse_cd_stacked \
            --weights-path policyengine_us_data/storage/calibration/w_cd.npy \
            --dataset-path policyengine_us_data/storage/stratified_extended_cps_2023.h5 \
            --db-path policyengine_us_data/storage/policy_data.db \
            --output-dir policyengine_us_data/storage/cd_states

      - name: Run district-level validation tests
        run: |
          echo "Running validation tests..."
          pytest -m "district_level_validation" -v

      - name: Upload state files to GCS
        if: success()
        run: |
          GCS_DATE="${{ inputs.gcs_date || '2025-10-22-1721' }}"
          echo "Tests passed! Uploading state files to GCS..."
          gsutil -m cp policyengine_us_data/storage/cd_states/*.h5 gs://policyengine-calibration/$GCS_DATE/state_files/
          gsutil -m cp policyengine_us_data/storage/cd_states/*_household_mapping.csv gs://policyengine-calibration/$GCS_DATE/state_files/
          echo ""
          echo "✅ State files uploaded to gs://policyengine-calibration/$GCS_DATE/state_files/"

      - name: Report validation failure
        if: failure()
        run: |
          echo "❌ District-level calibration validation FAILED"
          echo "Check the test output above for details"
          echo "State files were NOT uploaded to GCS"
          exit 1
