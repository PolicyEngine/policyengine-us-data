{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo-Stacking Calibration Walkthrough\n",
    "\n",
    "This notebook validates the sparse matrix construction and dataset creation pipeline for CD-level calibration. It traces a single household through the system to verify correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Matrix Construction\n",
    "\n",
    "Build the sparse calibration matrix `X_sparse` where rows are targets and columns are (household × CD) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baogorek/envs/pe/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_LITE == False\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from policyengine_us import Microsimulation\n",
    "from policyengine_us_data.storage import STORAGE_FOLDER\n",
    "from policyengine_us_data.datasets.cps.geo_stacking_calibration.metrics_matrix_geo_stacking_sparse import (\n",
    "    SparseGeoStackingMatrixBuilder,\n",
    ")\n",
    "from policyengine_us_data.datasets.cps.geo_stacking_calibration.calibration_utils import (\n",
    "    create_target_groups,\n",
    ")\n",
    "from policyengine_us_data.datasets.cps.geo_stacking_calibration.household_tracer import HouseholdTracer\n",
    "from policyengine_us_data.datasets.cps.geo_stacking_calibration.create_sparse_cd_stacked import create_sparse_cd_stacked_dataset\n",
    "\n",
    "rng_ben = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = STORAGE_FOLDER / \"policy_data.db\"\n",
    "db_uri = f\"sqlite:///{db_path}\"\n",
    "builder = SparseGeoStackingMatrixBuilder(db_uri, time_period=2023)\n",
    "\n",
    "engine = create_engine(db_uri)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT sc.value as cd_geoid\n",
    "FROM strata s\n",
    "JOIN stratum_constraints sc ON s.stratum_id = sc.stratum_id\n",
    "WHERE s.stratum_group_id = 1\n",
    "  AND sc.constraint_variable = 'congressional_district_geoid'\n",
    "ORDER BY sc.value\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(query)).fetchall()\n",
    "    all_cd_geoids = [row[0] for row in result]\n",
    "\n",
    "cds_to_calibrate = all_cd_geoids\n",
    "dataset_uri = STORAGE_FOLDER / \"stratified_10k.h5\"\n",
    "sim = Microsimulation(dataset=str(dataset_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Target Groups ===\n",
      "\n",
      "National targets (each is a singleton group):\n",
      "  Group 0: alimony_expense = 12,554,181,166\n",
      "  Group 1: alimony_income = 12,554,181,166\n",
      "  Group 2: charitable_deduction = 63,061,583,407\n",
      "  Group 3: child_support_expense = 31,868,306,036\n",
      "  Group 4: child_support_received = 31,868,306,036\n",
      "  Group 5: eitc = 64,440,000,000\n",
      "  Group 6: health_insurance_premiums_without_medicare_part_b = 371,796,903,749\n",
      "  Group 7: income_tax = 2,176,481,000,000\n",
      "  Group 8: interest_deduction = 23,949,514,839\n",
      "  Group 9: medicaid = 841,806,132,462\n",
      "  Group 10: medical_expense_deduction = 11,009,051,176\n",
      "  Group 11: medicare_part_b_premiums = 108,159,099,272\n",
      "  Group 12: net_worth = 154,512,998,960,600\n",
      "  Group 13: other_medical_expenses = 268,466,335,694\n",
      "  Group 14: over_the_counter_health_expenses = 71,220,353,850\n",
      "  Group 15: person_count_aca_ptc>0 = 19,529,896\n",
      "  Group 16: person_count_medicaid>0 = 71,644,763\n",
      "  Group 17: person_count_ssn_card_type=NONE = 12,200,000\n",
      "  Group 18: qualified_business_income_deduction = 60,936,063,965\n",
      "  Group 19: real_estate_taxes = 482,853,121,752\n",
      "  Group 20: rent = 709,794,088,975\n",
      "  Group 21: salt_deduction = 20,518,360,556\n",
      "  Group 22: snap = 107,062,860,000\n",
      "  Group 23: social_security = 1,379,268,000,000\n",
      "  Group 24: spm_unit_capped_housing_subsidy = 33,799,718,523\n",
      "  Group 25: spm_unit_capped_work_childcare_expenses = 336,065,772,739\n",
      "  Group 26: ssi = 60,090,000,000\n",
      "  Group 27: tanf = 8,691,356,192\n",
      "  Group 28: tip_income = 51,375,572,154\n",
      "  Group 29: unemployment_compensation = 35,000,000,000\n",
      "\n",
      "Geographic targets (grouped by variable type):\n",
      "  Group 30: All CD Age Distribution (7848 targets)\n",
      "  Group 31: All CD Person Income Distribution (3924 targets)\n",
      "  Group 32: All CD Medicaid Enrollment (436 targets)\n",
      "  Group 33: All CD Tax Units dividend_income>0 (436 targets)\n",
      "  Group 34: All CD Tax Units eitc_child_count==0 (436 targets)\n",
      "  Group 35: All CD Tax Units eitc_child_count==1 (436 targets)\n",
      "  Group 36: All CD Tax Units eitc_child_count==2 (436 targets)\n",
      "  Group 37: All CD Tax Units eitc_child_count>2 (436 targets)\n",
      "  Group 38: All CD Tax Units income_tax>0 (436 targets)\n",
      "  Group 39: All CD Tax Units income_tax_before_credits>0 (436 targets)\n",
      "  Group 40: All CD Tax Units medical_expense_deduction>0 (436 targets)\n",
      "  Group 41: All CD Tax Units net_capital_gains>0 (436 targets)\n",
      "  Group 42: All CD Tax Units qualified_business_income_deduction>0 (436 targets)\n",
      "  Group 43: All CD Tax Units qualified_dividend_income>0 (436 targets)\n",
      "  Group 44: All CD Tax Units real_estate_taxes>0 (436 targets)\n",
      "  Group 45: All CD Tax Units refundable_ctc>0 (436 targets)\n",
      "  Group 46: All CD Tax Units rental_income>0 (436 targets)\n",
      "  Group 47: All CD Tax Units salt>0 (436 targets)\n",
      "  Group 48: All CD Tax Units self_employment_income>0 (436 targets)\n",
      "  Group 49: All CD Tax Units tax_exempt_interest_income>0 (436 targets)\n",
      "  Group 50: All CD Tax Units tax_unit_partnership_s_corp_income>0 (436 targets)\n",
      "  Group 51: All CD Tax Units taxable_interest_income>0 (436 targets)\n",
      "  Group 52: All CD Tax Units taxable_ira_distributions>0 (436 targets)\n",
      "  Group 53: All CD Tax Units taxable_pension_income>0 (436 targets)\n",
      "  Group 54: All CD Tax Units taxable_social_security>0 (436 targets)\n",
      "  Group 55: All CD Tax Units unemployment_compensation>0 (436 targets)\n",
      "  Group 56: All CD AGI Total Amount (436 targets)\n",
      "  Group 57: All CD Dividend Income (436 targets)\n",
      "  Group 58: All CD Eitc (1744 targets)\n",
      "  Group 59: All CD SNAP Household Count (436 targets)\n",
      "  Group 60: All CD Income Tax (436 targets)\n",
      "  Group 61: All CD Income Tax Before Credits (436 targets)\n",
      "  Group 62: All CD Medical Expense Deduction (436 targets)\n",
      "  Group 63: All CD Net Capital Gains (436 targets)\n",
      "  Group 64: All CD Qualified Business Income Deduction (436 targets)\n",
      "  Group 65: All CD Qualified Dividend Income (436 targets)\n",
      "  Group 66: All CD Real Estate Taxes (436 targets)\n",
      "  Group 67: All CD Refundable Ctc (436 targets)\n",
      "  Group 68: All CD Rental Income (436 targets)\n",
      "  Group 69: All CD Salt (436 targets)\n",
      "  Group 70: All CD Self Employment Income (436 targets)\n",
      "  Group 71: State-level SNAP Cost (State) (51 targets)\n",
      "  Group 72: All CD Tax Exempt Interest Income (436 targets)\n",
      "  Group 73: All CD Tax Unit Partnership S Corp Income (436 targets)\n",
      "  Group 74: All CD Taxable Interest Income (436 targets)\n",
      "  Group 75: All CD Taxable Ira Distributions (436 targets)\n",
      "  Group 76: All CD Taxable Pension Income (436 targets)\n",
      "  Group 77: All CD Taxable Social Security (436 targets)\n",
      "  Group 78: All CD Unemployment Compensation (436 targets)\n",
      "\n",
      "Total groups created: 79\n",
      "========================================\n",
      "X_sparse shape: (33217, 4612880)\n",
      "Number of target groups: 79\n"
     ]
    }
   ],
   "source": [
    "targets_df, X_sparse, household_id_mapping = (\n",
    "    builder.build_stacked_matrix_sparse(\n",
    "        \"congressional_district\", cds_to_calibrate, sim\n",
    "    )\n",
    ")\n",
    "\n",
    "target_groups, group_info = create_target_groups(targets_df)\n",
    "tracer = HouseholdTracer(targets_df, X_sparse, household_id_mapping, cds_to_calibrate, sim)\n",
    "\n",
    "print(f\"X_sparse shape: {X_sparse.shape}\")\n",
    "print(f\"Number of target groups: {len(set(target_groups))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Understanding the Row Catalog\n",
    "\n",
    "The tracer provides a catalog of what each row (target) represents. We'll examine Group 71: SNAP Cost (State) - 51 targets across 51 states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MATRIX STRUCTURE BREAKDOWN\n",
      "================================================================================\n",
      "\n",
      "Matrix dimensions: 33217 rows × 4612880 columns\n",
      "  Rows = 33217 targets\n",
      "  Columns = 10580 households × 436 CDs\n",
      "           = 10,580 × 436 = 4,612,880\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "COLUMN STRUCTURE (Households stacked by CD)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Showing first and last 10 CDs of 436 total:\n",
      "\n",
      "First 10 CDs:\n",
      "cd_geoid  start_col  end_col  n_households  example_household_id\n",
      "    1001          0    10579         10580                    25\n",
      "     101      10580    21159         10580                    25\n",
      "     102      21160    31739         10580                    25\n",
      "     103      31740    42319         10580                    25\n",
      "     104      42320    52899         10580                    25\n",
      "     105      52900    63479         10580                    25\n",
      "     106      63480    74059         10580                    25\n",
      "     107      74060    84639         10580                    25\n",
      "    1101      84640    95219         10580                    25\n",
      "    1201      95220   105799         10580                    25\n",
      "\n",
      "Last 10 CDs:\n",
      "cd_geoid  start_col  end_col  n_households  example_household_id\n",
      "     804    4507080  4517659         10580                    25\n",
      "     805    4517660  4528239         10580                    25\n",
      "     806    4528240  4538819         10580                    25\n",
      "     807    4538820  4549399         10580                    25\n",
      "     808    4549400  4559979         10580                    25\n",
      "     901    4559980  4570559         10580                    25\n",
      "     902    4570560  4581139         10580                    25\n",
      "     903    4581140  4591719         10580                    25\n",
      "     904    4591720  4602299         10580                    25\n",
      "     905    4602300  4612879         10580                    25\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ROW STRUCTURE (Targets by geography and variable)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Targets by geographic level:\n",
      "geographic_level  n_targets\n",
      "         unknown      33217\n",
      "\n",
      "Targets by stratum group:\n",
      "                  n_targets  n_unique_vars\n",
      "stratum_group_id                          \n",
      "2                      8284              2\n",
      "3                      3924              1\n",
      "4                       436              1\n",
      "5                       436              1\n",
      "6                      3488              2\n",
      "100                     872              2\n",
      "101                     872              2\n",
      "102                     872              2\n",
      "103                     872              2\n",
      "104                     872              2\n",
      "105                     872              2\n",
      "106                     872              2\n",
      "107                     872              2\n",
      "108                     872              2\n",
      "109                     872              2\n",
      "110                     872              2\n",
      "111                     872              2\n",
      "112                     872              2\n",
      "113                     872              2\n",
      "114                     872              2\n",
      "115                     872              2\n",
      "116                     872              2\n",
      "117                     872              2\n",
      "118                     872              2\n",
      "national                 30             28\n",
      "state_snap_cost          51              1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TARGET GROUPS (for loss calculation)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Creating Target Groups ===\n",
      "\n",
      "National targets (each is a singleton group):\n",
      "  Group 0: alimony_expense = 12,554,181,166\n",
      "  Group 1: alimony_income = 12,554,181,166\n",
      "  Group 2: charitable_deduction = 63,061,583,407\n",
      "  Group 3: child_support_expense = 31,868,306,036\n",
      "  Group 4: child_support_received = 31,868,306,036\n",
      "  Group 5: eitc = 64,440,000,000\n",
      "  Group 6: health_insurance_premiums_without_medicare_part_b = 371,796,903,749\n",
      "  Group 7: income_tax = 2,176,481,000,000\n",
      "  Group 8: interest_deduction = 23,949,514,839\n",
      "  Group 9: medicaid = 841,806,132,462\n",
      "  Group 10: medical_expense_deduction = 11,009,051,176\n",
      "  Group 11: medicare_part_b_premiums = 108,159,099,272\n",
      "  Group 12: net_worth = 154,512,998,960,600\n",
      "  Group 13: other_medical_expenses = 268,466,335,694\n",
      "  Group 14: over_the_counter_health_expenses = 71,220,353,850\n",
      "  Group 15: person_count_aca_ptc>0 = 19,529,896\n",
      "  Group 16: person_count_medicaid>0 = 71,644,763\n",
      "  Group 17: person_count_ssn_card_type=NONE = 12,200,000\n",
      "  Group 18: qualified_business_income_deduction = 60,936,063,965\n",
      "  Group 19: real_estate_taxes = 482,853,121,752\n",
      "  Group 20: rent = 709,794,088,975\n",
      "  Group 21: salt_deduction = 20,518,360,556\n",
      "  Group 22: snap = 107,062,860,000\n",
      "  Group 23: social_security = 1,379,268,000,000\n",
      "  Group 24: spm_unit_capped_housing_subsidy = 33,799,718,523\n",
      "  Group 25: spm_unit_capped_work_childcare_expenses = 336,065,772,739\n",
      "  Group 26: ssi = 60,090,000,000\n",
      "  Group 27: tanf = 8,691,356,192\n",
      "  Group 28: tip_income = 51,375,572,154\n",
      "  Group 29: unemployment_compensation = 35,000,000,000\n",
      "\n",
      "Geographic targets (grouped by variable type):\n",
      "  Group 30: All CD Age Distribution (7848 targets)\n",
      "  Group 31: All CD Person Income Distribution (3924 targets)\n",
      "  Group 32: All CD Medicaid Enrollment (436 targets)\n",
      "  Group 33: All CD Tax Units dividend_income>0 (436 targets)\n",
      "  Group 34: All CD Tax Units eitc_child_count==0 (436 targets)\n",
      "  Group 35: All CD Tax Units eitc_child_count==1 (436 targets)\n",
      "  Group 36: All CD Tax Units eitc_child_count==2 (436 targets)\n",
      "  Group 37: All CD Tax Units eitc_child_count>2 (436 targets)\n",
      "  Group 38: All CD Tax Units income_tax>0 (436 targets)\n",
      "  Group 39: All CD Tax Units income_tax_before_credits>0 (436 targets)\n",
      "  Group 40: All CD Tax Units medical_expense_deduction>0 (436 targets)\n",
      "  Group 41: All CD Tax Units net_capital_gains>0 (436 targets)\n",
      "  Group 42: All CD Tax Units qualified_business_income_deduction>0 (436 targets)\n",
      "  Group 43: All CD Tax Units qualified_dividend_income>0 (436 targets)\n",
      "  Group 44: All CD Tax Units real_estate_taxes>0 (436 targets)\n",
      "  Group 45: All CD Tax Units refundable_ctc>0 (436 targets)\n",
      "  Group 46: All CD Tax Units rental_income>0 (436 targets)\n",
      "  Group 47: All CD Tax Units salt>0 (436 targets)\n",
      "  Group 48: All CD Tax Units self_employment_income>0 (436 targets)\n",
      "  Group 49: All CD Tax Units tax_exempt_interest_income>0 (436 targets)\n",
      "  Group 50: All CD Tax Units tax_unit_partnership_s_corp_income>0 (436 targets)\n",
      "  Group 51: All CD Tax Units taxable_interest_income>0 (436 targets)\n",
      "  Group 52: All CD Tax Units taxable_ira_distributions>0 (436 targets)\n",
      "  Group 53: All CD Tax Units taxable_pension_income>0 (436 targets)\n",
      "  Group 54: All CD Tax Units taxable_social_security>0 (436 targets)\n",
      "  Group 55: All CD Tax Units unemployment_compensation>0 (436 targets)\n",
      "  Group 56: All CD AGI Total Amount (436 targets)\n",
      "  Group 57: All CD Dividend Income (436 targets)\n",
      "  Group 58: All CD Eitc (1744 targets)\n",
      "  Group 59: All CD SNAP Household Count (436 targets)\n",
      "  Group 60: All CD Income Tax (436 targets)\n",
      "  Group 61: All CD Income Tax Before Credits (436 targets)\n",
      "  Group 62: All CD Medical Expense Deduction (436 targets)\n",
      "  Group 63: All CD Net Capital Gains (436 targets)\n",
      "  Group 64: All CD Qualified Business Income Deduction (436 targets)\n",
      "  Group 65: All CD Qualified Dividend Income (436 targets)\n",
      "  Group 66: All CD Real Estate Taxes (436 targets)\n",
      "  Group 67: All CD Refundable Ctc (436 targets)\n",
      "  Group 68: All CD Rental Income (436 targets)\n",
      "  Group 69: All CD Salt (436 targets)\n",
      "  Group 70: All CD Self Employment Income (436 targets)\n",
      "  Group 71: State-level SNAP Cost (State) (51 targets)\n",
      "  Group 72: All CD Tax Exempt Interest Income (436 targets)\n",
      "  Group 73: All CD Tax Unit Partnership S Corp Income (436 targets)\n",
      "  Group 74: All CD Taxable Interest Income (436 targets)\n",
      "  Group 75: All CD Taxable Ira Distributions (436 targets)\n",
      "  Group 76: All CD Taxable Pension Income (436 targets)\n",
      "  Group 77: All CD Taxable Social Security (436 targets)\n",
      "  Group 78: All CD Unemployment Compensation (436 targets)\n",
      "\n",
      "Total groups created: 79\n",
      "========================================\n",
      "  Group 0: National alimony_expense (1 target, value=12,554,181,166) - rows [0]\n",
      "  Group 1: National alimony_income (1 target, value=12,554,181,166) - rows [1]\n",
      "  Group 2: National charitable_deduction (1 target, value=63,061,583,407) - rows [2]\n",
      "  Group 3: National child_support_expense (1 target, value=31,868,306,036) - rows [3]\n",
      "  Group 4: National child_support_received (1 target, value=31,868,306,036) - rows [4]\n",
      "  Group 5: National eitc (1 target, value=64,440,000,000) - rows [5]\n",
      "  Group 6: National health_insurance_premiums_without_medicare_part_b (1 target, value=371,796,903,749) - rows [6]\n",
      "  Group 7: National income_tax (1 target, value=2,176,481,000,000) - rows [7]\n",
      "  Group 8: National interest_deduction (1 target, value=23,949,514,839) - rows [8]\n",
      "  Group 9: National medicaid (1 target, value=841,806,132,462) - rows [9]\n",
      "  Group 10: National medical_expense_deduction (1 target, value=11,009,051,176) - rows [10]\n",
      "  Group 11: National medicare_part_b_premiums (1 target, value=108,159,099,272) - rows [11]\n",
      "  Group 12: National net_worth (1 target, value=154,512,998,960,600) - rows [12]\n",
      "  Group 13: National other_medical_expenses (1 target, value=268,466,335,694) - rows [13]\n",
      "  Group 14: National over_the_counter_health_expenses (1 target, value=71,220,353,850) - rows [14]\n",
      "  Group 15: National person_count_aca_ptc>0 (1 target, value=19,529,896) - rows [15]\n",
      "  Group 16: National person_count_medicaid>0 (1 target, value=71,644,763) - rows [16]\n",
      "  Group 17: National person_count_ssn_card_type=NONE (1 target, value=12,200,000) - rows [17]\n",
      "  Group 18: National qualified_business_income_deduction (1 target, value=60,936,063,965) - rows [18]\n",
      "  Group 19: National real_estate_taxes (1 target, value=482,853,121,752) - rows [19]\n",
      "  Group 20: National rent (1 target, value=709,794,088,975) - rows [20]\n",
      "  Group 21: National salt_deduction (1 target, value=20,518,360,556) - rows [21]\n",
      "  Group 22: National snap (1 target, value=107,062,860,000) - rows [22]\n",
      "  Group 23: National social_security (1 target, value=1,379,268,000,000) - rows [23]\n",
      "  Group 24: National spm_unit_capped_housing_subsidy (1 target, value=33,799,718,523) - rows [24]\n",
      "  Group 25: National spm_unit_capped_work_childcare_expenses (1 target, value=336,065,772,739) - rows [25]\n",
      "  Group 26: National ssi (1 target, value=60,090,000,000) - rows [26]\n",
      "  Group 27: National tanf (1 target, value=8,691,356,192) - rows [27]\n",
      "  Group 28: National tip_income (1 target, value=51,375,572,154) - rows [28]\n",
      "  Group 29: National unemployment_compensation (1 target, value=35,000,000,000) - rows [29]\n",
      "  Group 30: Age Distribution (7848 targets across 436 geographies) - rows [50, 51, 52, '...', 33126, 33127]\n",
      "  Group 31: Person Income Distribution (3924 targets across 436 geographies) - rows [41, 42, 43, '...', 33108, 33109]\n",
      "  Group 32: Medicaid Enrollment (436 targets across 436 geographies) - rows [68, 144, 220, '...', 33052, 33128]\n",
      "  Group 33: Tax Units dividend_income>0 (436 targets across 436 geographies) - rows [77, 153, 229, '...', 33061, 33137]\n",
      "  Group 34: Tax Units eitc_child_count==0 (436 targets across 436 geographies) - rows [78, 154, 230, '...', 33062, 33138]\n",
      "  Group 35: Tax Units eitc_child_count==1 (436 targets across 436 geographies) - rows [79, 155, 231, '...', 33063, 33139]\n",
      "  Group 36: Tax Units eitc_child_count==2 (436 targets across 436 geographies) - rows [80, 156, 232, '...', 33064, 33140]\n",
      "  Group 37: Tax Units eitc_child_count>2 (436 targets across 436 geographies) - rows [81, 157, 233, '...', 33065, 33141]\n",
      "  Group 38: Tax Units income_tax>0 (436 targets across 436 geographies) - rows [83, 159, 235, '...', 33067, 33143]\n",
      "  Group 39: Tax Units income_tax_before_credits>0 (436 targets across 436 geographies) - rows [82, 158, 234, '...', 33066, 33142]\n",
      "  Group 40: Tax Units medical_expense_deduction>0 (436 targets across 436 geographies) - rows [84, 160, 236, '...', 33068, 33144]\n",
      "  Group 41: Tax Units net_capital_gains>0 (436 targets across 436 geographies) - rows [85, 161, 237, '...', 33069, 33145]\n",
      "  Group 42: Tax Units qualified_business_income_deduction>0 (436 targets across 436 geographies) - rows [86, 162, 238, '...', 33070, 33146]\n",
      "  Group 43: Tax Units qualified_dividend_income>0 (436 targets across 436 geographies) - rows [87, 163, 239, '...', 33071, 33147]\n",
      "  Group 44: Tax Units real_estate_taxes>0 (436 targets across 436 geographies) - rows [88, 164, 240, '...', 33072, 33148]\n",
      "  Group 45: Tax Units refundable_ctc>0 (436 targets across 436 geographies) - rows [89, 165, 241, '...', 33073, 33149]\n",
      "  Group 46: Tax Units rental_income>0 (436 targets across 436 geographies) - rows [90, 166, 242, '...', 33074, 33150]\n",
      "  Group 47: Tax Units salt>0 (436 targets across 436 geographies) - rows [91, 167, 243, '...', 33075, 33151]\n",
      "  Group 48: Tax Units self_employment_income>0 (436 targets across 436 geographies) - rows [92, 168, 244, '...', 33076, 33152]\n",
      "  Group 49: Tax Units tax_exempt_interest_income>0 (436 targets across 436 geographies) - rows [93, 169, 245, '...', 33077, 33153]\n",
      "  Group 50: Tax Units tax_unit_partnership_s_corp_income>0 (436 targets across 436 geographies) - rows [94, 170, 246, '...', 33078, 33154]\n",
      "  Group 51: Tax Units taxable_interest_income>0 (436 targets across 436 geographies) - rows [95, 171, 247, '...', 33079, 33155]\n",
      "  Group 52: Tax Units taxable_ira_distributions>0 (436 targets across 436 geographies) - rows [96, 172, 248, '...', 33080, 33156]\n",
      "  Group 53: Tax Units taxable_pension_income>0 (436 targets across 436 geographies) - rows [97, 173, 249, '...', 33081, 33157]\n",
      "  Group 54: Tax Units taxable_social_security>0 (436 targets across 436 geographies) - rows [98, 174, 250, '...', 33082, 33158]\n",
      "  Group 55: Tax Units unemployment_compensation>0 (436 targets across 436 geographies) - rows [99, 175, 251, '...', 33083, 33159]\n",
      "  Group 56: AGI Total Amount (436 targets across 436 geographies) - rows [30, 106, 182, '...', 33014, 33090]\n",
      "  Group 57: Dividend Income (436 targets across 436 geographies) - rows [31, 107, 183, '...', 33015, 33091]\n",
      "  Group 58: Eitc (1744 targets across 436 geographies) - rows [32, 33, 34, '...', 33094, 33095]\n",
      "  Group 59: SNAP Household Count (436 targets across 436 geographies) - rows [36, 112, 188, '...', 33020, 33096]\n",
      "  Group 60: Income Tax (436 targets across 436 geographies) - rows [38, 114, 190, '...', 33022, 33098]\n",
      "  Group 61: Income Tax Before Credits (436 targets across 436 geographies) - rows [37, 113, 189, '...', 33021, 33097]\n",
      "  Group 62: Medical Expense Deduction (436 targets across 436 geographies) - rows [39, 115, 191, '...', 33023, 33099]\n",
      "  Group 63: Net Capital Gains (436 targets across 436 geographies) - rows [40, 116, 192, '...', 33024, 33100]\n",
      "  Group 64: Qualified Business Income Deduction (436 targets across 436 geographies) - rows [69, 145, 221, '...', 33053, 33129]\n",
      "  Group 65: Qualified Dividend Income (436 targets across 436 geographies) - rows [70, 146, 222, '...', 33054, 33130]\n",
      "  Group 66: Real Estate Taxes (436 targets across 436 geographies) - rows [71, 147, 223, '...', 33055, 33131]\n",
      "  Group 67: Refundable Ctc (436 targets across 436 geographies) - rows [72, 148, 224, '...', 33056, 33132]\n",
      "  Group 68: Rental Income (436 targets across 436 geographies) - rows [73, 149, 225, '...', 33057, 33133]\n",
      "  Group 69: Salt (436 targets across 436 geographies) - rows [74, 150, 226, '...', 33058, 33134]\n",
      "  Group 70: Self Employment Income (436 targets across 436 geographies) - rows [75, 151, 227, '...', 33059, 33135]\n",
      "  Group 71: SNAP Cost (State) (51 targets across 51 geographies) - rows [33166, 33167, 33168, '...', 33215, 33216]\n",
      "  Group 72: Tax Exempt Interest Income (436 targets across 436 geographies) - rows [76, 152, 228, '...', 33060, 33136]\n",
      "  Group 73: Tax Unit Partnership S Corp Income (436 targets across 436 geographies) - rows [100, 176, 252, '...', 33084, 33160]\n",
      "  Group 74: Taxable Interest Income (436 targets across 436 geographies) - rows [101, 177, 253, '...', 33085, 33161]\n",
      "  Group 75: Taxable Ira Distributions (436 targets across 436 geographies) - rows [102, 178, 254, '...', 33086, 33162]\n",
      "  Group 76: Taxable Pension Income (436 targets across 436 geographies) - rows [103, 179, 255, '...', 33087, 33163]\n",
      "  Group 77: Taxable Social Security (436 targets across 436 geographies) - rows [104, 180, 256, '...', 33088, 33164]\n",
      "  Group 78: Unemployment Compensation (436 targets across 436 geographies) - rows [105, 181, 257, '...', 33089, 33165]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "tracer.print_matrix_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row info for first SNAP state target:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'row_index': 33166,\n",
       " 'variable': 'snap',\n",
       " 'variable_desc': 'snap_cost_state',\n",
       " 'geographic_id': '1',\n",
       " 'geographic_level': 'unknown',\n",
       " 'target_value': 2048985036.0,\n",
       " 'stratum_id': 9766,\n",
       " 'stratum_group_id': 'state_snap_cost'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_71 = tracer.get_group_rows(71)\n",
    "row_loc = group_71.iloc[0]['row_index']\n",
    "row_info = tracer.get_row_info(row_loc)\n",
    "var = row_info['variable']\n",
    "var_desc = row_info['variable_desc']\n",
    "target_geo_id = int(row_info['geographic_id'])\n",
    "\n",
    "print(\"Row info for first SNAP state target:\")\n",
    "row_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>variable</th>\n",
       "      <th>variable_desc</th>\n",
       "      <th>geographic_id</th>\n",
       "      <th>geographic_level</th>\n",
       "      <th>target_value</th>\n",
       "      <th>stratum_id</th>\n",
       "      <th>stratum_group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33166</th>\n",
       "      <td>33166</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2.048985e+09</td>\n",
       "      <td>9766</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33167</th>\n",
       "      <td>33167</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>10</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2.962075e+08</td>\n",
       "      <td>9773</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33168</th>\n",
       "      <td>33168</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>11</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3.793723e+08</td>\n",
       "      <td>9774</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33169</th>\n",
       "      <td>33169</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>6.756577e+09</td>\n",
       "      <td>9775</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33170</th>\n",
       "      <td>33170</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>13</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3.232508e+09</td>\n",
       "      <td>9776</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33171</th>\n",
       "      <td>33171</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>15</td>\n",
       "      <td>unknown</td>\n",
       "      <td>8.424059e+08</td>\n",
       "      <td>9777</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33172</th>\n",
       "      <td>33172</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2.494227e+08</td>\n",
       "      <td>9778</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33173</th>\n",
       "      <td>33173</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>17</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.440580e+09</td>\n",
       "      <td>9779</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33174</th>\n",
       "      <td>33174</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>18</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1.302143e+09</td>\n",
       "      <td>9780</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33175</th>\n",
       "      <td>33175</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>19</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.091406e+08</td>\n",
       "      <td>9781</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_index variable    variable_desc geographic_id geographic_level  \\\n",
       "33166      33166     snap  snap_cost_state             1          unknown   \n",
       "33167      33167     snap  snap_cost_state            10          unknown   \n",
       "33168      33168     snap  snap_cost_state            11          unknown   \n",
       "33169      33169     snap  snap_cost_state            12          unknown   \n",
       "33170      33170     snap  snap_cost_state            13          unknown   \n",
       "33171      33171     snap  snap_cost_state            15          unknown   \n",
       "33172      33172     snap  snap_cost_state            16          unknown   \n",
       "33173      33173     snap  snap_cost_state            17          unknown   \n",
       "33174      33174     snap  snap_cost_state            18          unknown   \n",
       "33175      33175     snap  snap_cost_state            19          unknown   \n",
       "\n",
       "       target_value  stratum_id stratum_group_id  \n",
       "33166  2.048985e+09        9766  state_snap_cost  \n",
       "33167  2.962075e+08        9773  state_snap_cost  \n",
       "33168  3.793723e+08        9774  state_snap_cost  \n",
       "33169  6.756577e+09        9775  state_snap_cost  \n",
       "33170  3.232508e+09        9776  state_snap_cost  \n",
       "33171  8.424059e+08        9777  state_snap_cost  \n",
       "33172  2.494227e+08        9778  state_snap_cost  \n",
       "33173  5.440580e+09        9779  state_snap_cost  \n",
       "33174  1.302143e+09        9780  state_snap_cost  \n",
       "33175  5.091406e+08        9781  state_snap_cost  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_snap = tracer.row_catalog[\n",
    "    (tracer.row_catalog['variable'] == row_info['variable']) &\n",
    "    (tracer.row_catalog['variable_desc'] == row_info['variable_desc'])\n",
    "].sort_values('geographic_id')\n",
    "\n",
    "assert state_snap.shape[0] == 51, f\"Expected 51 state SNAP targets, got {state_snap.shape[0]}\"\n",
    "state_snap.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Finding an Interesting Household\n",
    "\n",
    "We need a household with:\n",
    "- More than one person\n",
    "- More than one SPM unit\n",
    "- Each SPM unit has positive SNAP\n",
    "\n",
    "This tests that we correctly aggregate SNAP at the household level (sum across SPM units, not persons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>household_id</th>\n",
       "      <th>tax_unit_id</th>\n",
       "      <th>spm_unit_id</th>\n",
       "      <th>family_id</th>\n",
       "      <th>marital_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2501</td>\n",
       "      <td>25</td>\n",
       "      <td>2501</td>\n",
       "      <td>25001</td>\n",
       "      <td>251.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10301</td>\n",
       "      <td>103</td>\n",
       "      <td>10301</td>\n",
       "      <td>103001</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12501</td>\n",
       "      <td>125</td>\n",
       "      <td>12501</td>\n",
       "      <td>125001</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12502</td>\n",
       "      <td>125</td>\n",
       "      <td>12501</td>\n",
       "      <td>125001</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12503</td>\n",
       "      <td>125</td>\n",
       "      <td>12502</td>\n",
       "      <td>125001</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  household_id  tax_unit_id  spm_unit_id  family_id  \\\n",
       "0       2501            25         2501        25001      251.0   \n",
       "1      10301           103        10301       103001     1031.0   \n",
       "2      12501           125        12501       125001     1251.0   \n",
       "3      12502           125        12501       125001     1251.0   \n",
       "4      12503           125        12502       125001     1252.0   \n",
       "\n",
       "   marital_unit_id  \n",
       "0               20  \n",
       "1               80  \n",
       "2               99  \n",
       "3              101  \n",
       "4              100  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_rel = pd.DataFrame(\n",
    "    {\n",
    "        \"person_id\": sim.calculate(\"person_id\", map_to=\"person\").values,\n",
    "        \"household_id\": sim.calculate(\"household_id\", map_to=\"person\").values,\n",
    "        \"tax_unit_id\": sim.calculate(\"tax_unit_id\", map_to=\"person\").values,\n",
    "        \"spm_unit_id\": sim.calculate(\"spm_unit_id\", map_to=\"person\").values,\n",
    "        \"family_id\": sim.calculate(\"family_id\", map_to=\"person\").values,\n",
    "        \"marital_unit_id\": sim.calculate(\"marital_unit_id\", map_to=\"person\").values,\n",
    "    }\n",
    ")\n",
    "entity_rel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: SNAP values differ by entity level due to broadcasting:\n",
    "- `sim.calculate_dataframe(['spm_unit_id', 'snap'])` - rows are SPM units\n",
    "- `sim.calculate_dataframe(['household_id', 'snap'])` - rows are households\n",
    "- Person-level broadcasts the SPM unit's SNAP to each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_household_id</th>\n",
       "      <th>person_count</th>\n",
       "      <th>snap_min</th>\n",
       "      <th>snap_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>66231</td>\n",
       "      <td>2</td>\n",
       "      <td>2293.199951</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>82168</td>\n",
       "      <td>3</td>\n",
       "      <td>789.199951</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>91997</td>\n",
       "      <td>3</td>\n",
       "      <td>3592.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>112528</td>\n",
       "      <td>2</td>\n",
       "      <td>3236.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>128839</td>\n",
       "      <td>3</td>\n",
       "      <td>789.199951</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      person_household_id  person_count     snap_min  snap_unique\n",
       "3478                66231             2  2293.199951            2\n",
       "4396                82168             3   789.199951            3\n",
       "5109                91997             3  3592.000000            2\n",
       "6452               112528             2  3236.500000            2\n",
       "7388               128839             3   789.199951            2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_df = sim.calculate_dataframe(['person_household_id', 'person_id', 'snap'], map_to=\"person\")\n",
    "\n",
    "hh_stats = p_df.groupby('person_household_id').agg(\n",
    "    person_count=('person_id', 'nunique'),\n",
    "    snap_min=('snap', 'min'),\n",
    "    snap_unique=('snap', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "candidates = hh_stats[(hh_stats.person_count > 1) & (hh_stats.snap_min > 0) & (hh_stats.snap_unique > 1)]\n",
    "candidates.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_household_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>snap</th>\n",
       "      <th>__tmp_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15319</th>\n",
       "      <td>91997</td>\n",
       "      <td>9199706</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15320</th>\n",
       "      <td>91997</td>\n",
       "      <td>9199707</td>\n",
       "      <td>4333.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15321</th>\n",
       "      <td>91997</td>\n",
       "      <td>9199708</td>\n",
       "      <td>4333.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight  person_household_id  person_id    snap  __tmp_weights\n",
       "15319     0.0                91997    9199706  3592.0            0.0\n",
       "15320     0.0                91997    9199707  4333.5            0.0\n",
       "15321     0.0                91997    9199708  4333.5            0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_id = candidates.iloc[2]['person_household_id']\n",
    "p_df.loc[p_df.person_household_id == hh_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This household has 3 persons across 2 SPM units:\n",
    "- Person 1: SNAP = 3592.0\n",
    "- Persons 2,3: SNAP = 4333.5 (same SPM unit, broadcast)\n",
    "\n",
    "Correct household SNAP = 3592 + 4333.5 = **7925.5** (NOT 3592 + 4333.5 + 4333.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spm_unit_id</th>\n",
       "      <th>snap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>91997002</td>\n",
       "      <td>3592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>91997004</td>\n",
       "      <td>4333.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      weight  spm_unit_id    snap\n",
       "5357     0.0     91997002  3592.0\n",
       "5358     0.0     91997004  4333.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_snap_goal = 7925.5\n",
    "\n",
    "snap_df = sim.calculate_dataframe(['spm_unit_id', 'snap'])\n",
    "snap_subset = entity_rel.loc[entity_rel.household_id == hh_id]\n",
    "snap_df.loc[snap_df.spm_unit_id.isin(list(snap_subset.spm_unit_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Household 91997.0 is from state FIPS 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "household_id    91997\n",
       "state_fips         50\n",
       "Name: 5109, dtype: int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_df = sim.calculate_dataframe(['household_id', 'state_fips'])\n",
    "hh_loc = np.where(hh_df.household_id == hh_id)[0][0]\n",
    "hh_one = hh_df.iloc[hh_loc]\n",
    "hh_home_state = hh_one.state_fips\n",
    "\n",
    "print(f\"Household {hh_id} is from state FIPS {hh_home_state}\")\n",
    "hh_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Validate Matrix Values\n",
    "\n",
    "Each household appears as a column in X_sparse for every CD (436 times). For state-level SNAP targets, the matrix value should be:\n",
    "- `hh_snap_goal` if the CD is in the household's home state\n",
    "- `0` if the CD is in a different state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 436 CD column values validated for household 91997.0\n"
     ]
    }
   ],
   "source": [
    "hh_col_lku = tracer.get_household_column_positions(hh_id)\n",
    "\n",
    "for cd in hh_col_lku.keys():\n",
    "    hh_away_state = int(cd) // 100\n",
    "    col_loc = hh_col_lku[cd]\n",
    "    col_info = tracer.get_column_info(col_loc)\n",
    "    \n",
    "    assert col_info['household_id'] == hh_id\n",
    "    \n",
    "    value_lku = tracer.lookup_matrix_cell(row_idx=row_loc, col_idx=col_loc)\n",
    "    assert value_lku['household']['household_id'] == hh_id\n",
    "    \n",
    "    metric = value_lku['matrix_value']\n",
    "    assert X_sparse[row_loc, col_loc] == metric\n",
    "    \n",
    "    if hh_away_state != target_geo_id:\n",
    "        assert metric == 0, f\"Expected 0 for CD {cd} (state {hh_away_state}), got {metric}\"\n",
    "    else:\n",
    "        assert metric == hh_snap_goal, f\"Expected {hh_snap_goal} for CD {cd}, got {metric}\"\n",
    "\n",
    "print(f\"All {len(hh_col_lku)} CD column values validated for household {hh_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Create Sparse Dataset from Weights\n",
    "\n",
    "Test `create_sparse_cd_stacked_dataset` which reconstructs an h5 file from weight vectors. We verify:\n",
    "1. Household appears in mapping file for CDs with non-zero weight\n",
    "2. New household IDs correctly map back to originals\n",
    "3. SNAP values are preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nonzero = 500000\n",
    "total_size = X_sparse.shape[1]\n",
    "\n",
    "w = np.zeros(total_size)\n",
    "nonzero_indices = rng_ben.choice(total_size, n_nonzero, replace=False)\n",
    "w[nonzero_indices] = 2\n",
    "\n",
    "cd1 = '103'\n",
    "cd2 = '3703'\n",
    "output_dir = './temp'\n",
    "w[hh_col_lku[cd1]] = 1.5\n",
    "w[hh_col_lku[cd2]] = 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subset of 2 CDs: 103, 3703...\n",
      "Output path: ./temp/mapping1.h5\n",
      "\n",
      "Original dataset has 10,580 households\n",
      "Extracted weights for 2 CDs from full weight matrix\n",
      "Total active household-CD pairs: 2,204\n",
      "Total weight in W matrix: 4,407\n",
      "Processing CD 3703 (2/2)...\n",
      "\n",
      "Combining 2 CD DataFrames...\n",
      "Total households across all CDs: 2,204\n",
      "Combined DataFrame shape: (6821, 241)\n",
      "\n",
      "Weights in combined_df BEFORE reindexing:\n",
      "  HH weight sum: 0.01M\n",
      "  Person weight sum: 0.01M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Reindexing all entity IDs using 25k ranges per CD...\n",
      "  Created 2,204 unique households across 2 CDs\n",
      "  Reindexing persons using 25k ranges...\n",
      "  Reindexing tax units...\n",
      "  Reindexing SPM units...\n",
      "  Reindexing marital units...\n",
      "  Final persons: 6,821\n",
      "  Final households: 2,204\n",
      "  Final tax units: 3,159\n",
      "  Final SPM units: 2,313\n",
      "  Final marital units: 5,230\n",
      "\n",
      "Weights in combined_df AFTER reindexing:\n",
      "  HH weight sum: 0.01M\n",
      "  Person weight sum: 0.01M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Overflow check:\n",
      "  Max person ID after reindexing: 10,203,295\n",
      "  Max person ID × 100: 1,020,329,500\n",
      "  int32 max: 2,147,483,647\n",
      "  ✓ No overflow risk!\n",
      "\n",
      "Creating Dataset from combined DataFrame...\n",
      "Building simulation from Dataset...\n",
      "\n",
      "Saving to ./temp/mapping1.h5...\n",
      "Base dataset has 230 variables\n",
      "Variables saved: 241\n",
      "Variables skipped: 2757\n",
      "Sparse CD-stacked dataset saved successfully!\n",
      "Household mapping saved to ./temp/mappings/mapping1_household_mapping.csv\n",
      "\n",
      "Verifying saved file...\n",
      "  Final households: 2,204\n",
      "  Final persons: 6,821\n",
      "  Total population (from household weights): 4,407\n",
      "  Total population (from person weights): 13,640\n",
      "  Average persons per household: 3.09\n",
      "Output dataset shape: (2204, 4)\n"
     ]
    }
   ],
   "source": [
    "output_path = f\"{output_dir}/mapping1.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    cds_to_calibrate,\n",
    "    cd_subset=[cd1, cd2],\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    ")\n",
    "\n",
    "sim_test = Microsimulation(dataset=output_path)\n",
    "df_test = sim_test.calculate_dataframe([\n",
    "    'congressional_district_geoid',\n",
    "    'household_id', 'household_weight', 'snap'])\n",
    "\n",
    "print(f\"Output dataset shape: {df_test.shape}\")\n",
    "assert np.isclose(df_test.shape[0] / 2 * 436, n_nonzero, rtol=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_household_id</th>\n",
       "      <th>original_household_id</th>\n",
       "      <th>congressional_district</th>\n",
       "      <th>state_fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>75558</td>\n",
       "      <td>91997</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>5200557</td>\n",
       "      <td>91997</td>\n",
       "      <td>3703</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      new_household_id  original_household_id  congressional_district  \\\n",
       "1115             75558                  91997                     103   \n",
       "1116           5200557                  91997                    3703   \n",
       "\n",
       "      state_fips  \n",
       "1115           1  \n",
       "1116          37  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.read_csv(f\"{output_dir}/mappings/mapping1_household_mapping.csv\")\n",
    "match = mapping.loc[mapping.original_household_id == hh_id].shape[0]\n",
    "assert match == 2, f\"Household should appear twice (once per CD), got {match}\"\n",
    "\n",
    "hh_mapping = mapping.loc[mapping.original_household_id == hh_id]\n",
    "hh_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD 103: weight=1.5, snap=7925.5\n"
     ]
    }
   ],
   "source": [
    "df_test_cd1 = df_test.loc[df_test.congressional_district_geoid == int(cd1)]\n",
    "df_test_cd2 = df_test.loc[df_test.congressional_district_geoid == int(cd2)]\n",
    "\n",
    "hh_mapping_cd1 = hh_mapping.loc[hh_mapping.congressional_district == int(cd1)]\n",
    "new_hh_id_cd1 = hh_mapping_cd1['new_household_id'].values[0]\n",
    "\n",
    "assert hh_mapping_cd1.shape[0] == 1\n",
    "assert hh_mapping_cd1.original_household_id.values[0] == hh_id\n",
    "\n",
    "w_hh_cd1 = w[hh_col_lku[cd1]]\n",
    "assert_cd1_df = df_test_cd1.loc[df_test_cd1.household_id == new_hh_id_cd1]\n",
    "\n",
    "assert np.isclose(assert_cd1_df.household_weight.values[0], w_hh_cd1, atol=0.001)\n",
    "assert np.isclose(assert_cd1_df.snap.values[0], hh_snap_goal, atol=0.001)\n",
    "\n",
    "print(f\"CD {cd1}: weight={w_hh_cd1}, snap={assert_cd1_df.snap.values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD 3703: weight=1.7, snap=7925.5\n"
     ]
    }
   ],
   "source": [
    "hh_mapping_cd2 = hh_mapping.loc[hh_mapping.congressional_district == int(cd2)]\n",
    "new_hh_id_cd2 = hh_mapping_cd2['new_household_id'].values[0]\n",
    "\n",
    "assert hh_mapping_cd2.shape[0] == 1\n",
    "assert hh_mapping_cd2.original_household_id.values[0] == hh_id\n",
    "\n",
    "w_hh_cd2 = w[hh_col_lku[cd2]]\n",
    "assert_cd2_df = df_test_cd2.loc[df_test_cd2.household_id == new_hh_id_cd2]\n",
    "\n",
    "assert np.isclose(assert_cd2_df.household_weight.values[0], w_hh_cd2, atol=0.001)\n",
    "assert np.isclose(assert_cd2_df.snap.values[0], hh_snap_goal, atol=0.001)\n",
    "\n",
    "print(f\"CD {cd2}: weight={w_hh_cd2}, snap={assert_cd2_df.snap.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Zero weight excludes household from mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subset of 1 CDs: 3703...\n",
      "Output path: ./temp/3703.h5\n",
      "\n",
      "Original dataset has 10,580 households\n",
      "Extracted weights for 1 CDs from full weight matrix\n",
      "Total active household-CD pairs: 1,072\n",
      "Total weight in W matrix: 2,144\n",
      "Processing CD 3703 (1/1)...\n",
      "\n",
      "Combining 1 CD DataFrames...\n",
      "Total households across all CDs: 1,072\n",
      "Combined DataFrame shape: (3293, 241)\n",
      "\n",
      "Weights in combined_df BEFORE reindexing:\n",
      "  HH weight sum: 0.01M\n",
      "  Person weight sum: 0.01M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Reindexing all entity IDs using 25k ranges per CD...\n",
      "  Created 1,072 unique households across 1 CDs\n",
      "  Reindexing persons using 25k ranges...\n",
      "  Reindexing tax units...\n",
      "  Reindexing SPM units...\n",
      "  Reindexing marital units...\n",
      "  Final persons: 3,293\n",
      "  Final households: 1,072\n",
      "  Final tax units: 1,518\n",
      "  Final SPM units: 1,118\n",
      "  Final marital units: 2,520\n",
      "\n",
      "Weights in combined_df AFTER reindexing:\n",
      "  HH weight sum: 0.01M\n",
      "  Person weight sum: 0.01M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Overflow check:\n",
      "  Max person ID after reindexing: 10,203,292\n",
      "  Max person ID × 100: 1,020,329,200\n",
      "  int32 max: 2,147,483,647\n",
      "  ✓ No overflow risk!\n",
      "\n",
      "Creating Dataset from combined DataFrame...\n",
      "Building simulation from Dataset...\n",
      "\n",
      "Saving to ./temp/3703.h5...\n",
      "Base dataset has 230 variables\n",
      "Variables saved: 241\n",
      "Variables skipped: 2757\n",
      "Sparse CD-stacked dataset saved successfully!\n",
      "Household mapping saved to ./temp/mappings/3703_household_mapping.csv\n",
      "\n",
      "Verifying saved file...\n",
      "  Final households: 1,072\n",
      "  Final persons: 3,293\n",
      "  Total population (from household weights): 2,144\n",
      "  Total population (from person weights): 6,586\n",
      "  Average persons per household: 3.07\n",
      "Confirmed: household 91997.0 excluded from CD 3703 mapping when weight=0\n"
     ]
    }
   ],
   "source": [
    "w[hh_col_lku[cd2]] = 0\n",
    "\n",
    "output_path = f\"{output_dir}/{cd2}.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    cds_to_calibrate,\n",
    "    cd_subset=[cd2],\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    ")\n",
    "\n",
    "sim_test = Microsimulation(dataset=output_path)\n",
    "df_test = sim_test.calculate_dataframe(['household_id', 'household_weight', 'snap'])\n",
    "\n",
    "cd2_mapping = pd.read_csv(f\"{output_dir}/mappings/{cd2}_household_mapping.csv\")\n",
    "match = cd2_mapping.loc[cd2_mapping.original_household_id == hh_id].shape[0]\n",
    "assert match == 0, f\"Household with zero weight should not appear in mapping, got {match}\"\n",
    "\n",
    "print(f\"Confirmed: household {hh_id} excluded from CD {cd2} mapping when weight=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: End-to-End Validation (X @ w == sim.calculate)\n",
    "\n",
    "The ultimate test: verify that matrix multiplication `X_sparse @ w` matches what we get from running the simulation on the reconstructed h5 file.\n",
    "\n",
    "With `freeze_calculated_vars=True`, state-dependent variables like SNAP are saved to the h5 file to prevent recalculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = X_sparse.shape[1]\n",
    "w = np.zeros(total_size)\n",
    "n_nonzero = 50000\n",
    "nonzero_indices = rng_ben.choice(total_size, n_nonzero, replace=False)\n",
    "w[nonzero_indices] = 7\n",
    "w[hh_col_lku[cd1]] = 11\n",
    "w[hh_col_lku[cd2]] = 12\n",
    "\n",
    "assert np.sum(w > 0) <= n_nonzero + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all 436 congressional districts\n",
      "Output path: ./temp/national.h5\n",
      "\n",
      "Original dataset has 10,580 households\n",
      "Total active household-CD pairs: 1,785,889\n",
      "Total weight in W matrix: 115,718,240\n",
      "Processing CD 1201 (10/436)...\n",
      "Processing CD 1211 (20/436)...\n",
      "Processing CD 1221 (30/436)...\n",
      "Processing CD 1303 (40/436)...\n",
      "Processing CD 1313 (50/436)...\n",
      "Processing CD 1705 (60/436)...\n",
      "Processing CD 1715 (70/436)...\n",
      "Processing CD 1808 (80/436)...\n",
      "Processing CD 201 (90/436)...\n",
      "Processing CD 2204 (100/436)...\n",
      "Processing CD 2406 (110/436)...\n",
      "Processing CD 2508 (120/436)...\n",
      "Processing CD 2609 (130/436)...\n",
      "Processing CD 2706 (140/436)...\n",
      "Processing CD 2904 (150/436)...\n",
      "Processing CD 3201 (160/436)...\n",
      "Processing CD 3405 (170/436)...\n",
      "Processing CD 3503 (180/436)...\n",
      "Processing CD 3610 (190/436)...\n",
      "Processing CD 3620 (200/436)...\n",
      "Processing CD 3704 (210/436)...\n",
      "Processing CD 3714 (220/436)...\n",
      "Processing CD 3909 (230/436)...\n",
      "Processing CD 4004 (240/436)...\n",
      "Processing CD 409 (250/436)...\n",
      "Processing CD 4204 (260/436)...\n",
      "Processing CD 4214 (270/436)...\n",
      "Processing CD 4505 (280/436)...\n",
      "Processing CD 4707 (290/436)...\n",
      "Processing CD 4808 (300/436)...\n",
      "Processing CD 4818 (310/436)...\n",
      "Processing CD 4828 (320/436)...\n",
      "Processing CD 4838 (330/436)...\n",
      "Processing CD 5101 (340/436)...\n",
      "Processing CD 5111 (350/436)...\n",
      "Processing CD 5310 (360/436)...\n",
      "Processing CD 5508 (370/436)...\n",
      "Processing CD 609 (380/436)...\n",
      "Processing CD 619 (390/436)...\n",
      "Processing CD 629 (400/436)...\n",
      "Processing CD 639 (410/436)...\n",
      "Processing CD 649 (420/436)...\n",
      "Processing CD 807 (430/436)...\n",
      "Processing CD 905 (436/436)...\n",
      "\n",
      "Combining 436 CD DataFrames...\n",
      "Total households across all CDs: 1,785,889\n",
      "Combined DataFrame shape: (5466133, 241)\n",
      "\n",
      "Weights in combined_df BEFORE reindexing:\n",
      "  HH weight sum: 334.66M\n",
      "  Person weight sum: 334.66M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Reindexing all entity IDs using 25k ranges per CD...\n",
      "  Created 1,785,889 unique households across 436 CDs\n",
      "  Reindexing persons using 25k ranges...\n",
      "  Reindexing tax units...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/national.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sparse_cd_stacked_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcds_to_calibrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset_uri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_calculated_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devl/policyengine-us-data/policyengine_us_data/datasets/cps/geo_stacking_calibration/create_sparse_cd_stacked.py:766\u001b[0m, in \u001b[0;36mcreate_sparse_cd_stacked_dataset\u001b[0;34m(w, cds_to_calibrate, cd_subset, output_path, dataset_path, freeze_calculated_vars)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;66;03m# Create mapping for this household's tax units\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m old_tax \u001b[38;5;129;01min\u001b[39;00m unique_tax_in_hh:\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# Update all persons with this tax unit ID in this household\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     mask \u001b[38;5;241m=\u001b[39m (\u001b[43mcombined_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhh_id_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhh_id\u001b[49m) \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m    767\u001b[0m         combined_df[person_tax_unit_col] \u001b[38;5;241m==\u001b[39m old_tax\n\u001b[1;32m    768\u001b[0m     )\n\u001b[1;32m    769\u001b[0m     combined_df\u001b[38;5;241m.\u001b[39mloc[mask, person_tax_unit_col] \u001b[38;5;241m=\u001b[39m new_tax_id\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;66;03m# Also update tax_unit_id if it exists in the DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/pe/lib/python3.13/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/pe/lib/python3.13/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/pe/lib/python3.13/site-packages/pandas/core/series.py:6130\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6127\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6128\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6130\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/envs/pe/lib/python3.13/site-packages/pandas/core/ops/array_ops.py:347\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/envs/pe/lib/python3.13/site-packages/pandas/core/ops/array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    222\u001b[0m     ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/pe/lib/python3.13/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/envs/pe/lib/python3.13/site-packages/pandas/core/computation/expressions.py:108\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    105\u001b[0m b_value \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mop_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m b_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_value\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# numexpr raises eg for array ** array with integers\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pydata/numexpr/issues/379)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/pe/lib/python3.13/site-packages/numexpr/necompiler.py:979\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, sanitize, _frame_depth, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m e \u001b[38;5;241m=\u001b[39m validate(ex, local_dict\u001b[38;5;241m=\u001b[39mlocal_dict, global_dict\u001b[38;5;241m=\u001b[39mglobal_dict,\n\u001b[1;32m    976\u001b[0m              out\u001b[38;5;241m=\u001b[39mout, order\u001b[38;5;241m=\u001b[39morder, casting\u001b[38;5;241m=\u001b[39mcasting,\n\u001b[1;32m    977\u001b[0m              _frame_depth\u001b[38;5;241m=\u001b[39m_frame_depth, sanitize\u001b[38;5;241m=\u001b[39msanitize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mre_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_frame_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_frame_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/envs/pe/lib/python3.13/site-packages/numexpr/necompiler.py:1012\u001b[0m, in \u001b[0;36mre_evaluate\u001b[0;34m(local_dict, global_dict, _frame_depth)\u001b[0m\n\u001b[1;32m   1010\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m _numexpr_last\u001b[38;5;241m.\u001b[39ml[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# with evaluate_lock:\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_path = f\"{output_dir}/national.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    cds_to_calibrate,\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    "    freeze_calculated_vars=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_test = Microsimulation(dataset=output_path)\n",
    "hh_snap_df = pd.DataFrame(sim_test.calculate_dataframe([\n",
    "    \"household_id\", \"household_weight\", \"congressional_district_geoid\", \"state_fips\", \"snap\"])\n",
    ")\n",
    "\n",
    "assert np.sum(w > 0) == hh_snap_df.shape[0], f\"Expected {np.sum(w > 0)} rows, got {hh_snap_df.shape[0]}\"\n",
    "hh_snap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Target row info: {row_info}\")\n",
    "\n",
    "y_hat = X_sparse @ w\n",
    "snap_hat_geo1 = y_hat[row_loc]\n",
    "\n",
    "geo_1_df = hh_snap_df.loc[hh_snap_df.state_fips == 1]\n",
    "y_hat_sim = np.sum(geo_1_df.snap.values * geo_1_df.household_weight.values)\n",
    "\n",
    "print(f\"Matrix multiplication (X @ w)[{row_loc}] = {snap_hat_geo1:,.2f}\")\n",
    "print(f\"Simulation sum(snap * weight) for state 1 = {y_hat_sim:,.2f}\")\n",
    "\n",
    "# Check if household counts match\n",
    "n_matrix = np.sum(X_sparse[row_loc, :].toarray() > 0)\n",
    "n_sim = (geo_1_df.snap > 0).sum()\n",
    "print(f\"Matrix nonzero: {n_matrix}, Sim nonzero: {n_sim}\")\n",
    "\n",
    "# Check total weights\n",
    "w_in_state = sum(w[hh_col_lku[cd]] for cd in hh_col_lku if int(cd)//100 == 1)\n",
    "print(f\"Weight from matrix columns: {w_in_state}\")\n",
    "print(f\"Weight from sim: {geo_1_df.household_weight.sum()}\")\n",
    "\n",
    "assert np.isclose(y_hat_sim, snap_hat_geo1, atol=10), f\"Mismatch: {y_hat_sim} vs {snap_hat_geo1}\"\n",
    "print(\"\\nEnd-to-end validation PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4612880\n",
      "436\n",
      "[ 4.3249283  0.        16.083298  ...  6.212448   0.         0.       ]\n",
      "/home/baogorek/devl/policyengine-us-data/policyengine_us_data/storage/stratified_10k.h5\n",
      "Processing all 2 congressional districts\n",
      "Output path: ./temp/RI.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Households from base data set do not match households from weights",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_uri)\n\u001b[1;32m      7\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/RI.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sparse_cd_stacked_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3701\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3702\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset_uri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_calculated_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m51\u001b[39m):\n\u001b[1;32m     17\u001b[0m     row_loc \u001b[38;5;241m=\u001b[39m group_71\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/devl/policyengine-us-data/policyengine_us_data/datasets/cps/geo_stacking_calibration/create_sparse_cd_stacked.py:330\u001b[0m, in \u001b[0;36mcreate_sparse_cd_stacked_dataset\u001b[0;34m(w, cds_to_calibrate, cd_subset, output_path, dataset_path, freeze_calculated_vars)\u001b[0m\n\u001b[1;32m    327\u001b[0m n_households_from_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(cds_to_calibrate)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_households_from_weights \u001b[38;5;241m!=\u001b[39m n_households_orig:\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHouseholds from base data set do not match households from weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal dataset has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_households_orig\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m households\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# Process the weight vector to understand active household-CD pairs\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Households from base data set do not match households from weights"
     ]
    }
   ],
   "source": [
    "w = np.load('w_cd_20251126_131911.npy')\n",
    "print(len(w))\n",
    "print(len(cds_to_calibrate))\n",
    "\n",
    "print(w)\n",
    "print(dataset_uri)\n",
    "output_path = f\"{output_dir}/RI.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    cds_to_calibrate,\n",
    "    ['3701', '3702'],\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    "    freeze_calculated_vars=True,\n",
    ")\n",
    "\n",
    "for i in range(51):\n",
    "    row_loc = group_71.iloc[i]['row_index']\n",
    "    row_info = tracer.get_row_info(row_loc)\n",
    "    var = row_info['variable']\n",
    "    var_desc = row_info['variable_desc']\n",
    "    target_geo_id = int(row_info['geographic_id'])\n",
    "    if target_geo_id == 44:\n",
    "        break\n",
    "\n",
    "print(\"Row info for first SNAP state target:\")\n",
    "row_info\n",
    "print(f\"Target row info: {row_info}\")\n",
    "\n",
    "y_hat = X_sparse @ w\n",
    "snap_hat_geo44 = y_hat[row_loc]\n",
    "\n",
    "geo_44_df = hh_snap_df.loc[hh_snap_df.state_fips == 44]\n",
    "y_hat_sim = np.sum(geo_44_df.snap.values * geo_44_df.household_weight.values)\n",
    "\n",
    "print(f\"Matrix multiplication (X @ w)[{row_loc}] = {snap_hat_geo1:,.2f}\")\n",
    "print(f\"Simulation sum(snap * weight) for state 44 = {y_hat_sim:,.2f}\")\n",
    "\n",
    "assert np.isclose(y_hat_sim, snap_hat_geo1, atol=10), f\"Mismatch: {y_hat_sim} vs {snap_hat_geo44}\"\n",
    "print(\"\\nEnd-to-end validation PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists('./temp'):\n",
    "    shutil.rmtree('./temp')\n",
    "    print(\"Cleaned up ./temp directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f\"{output_dir}/3714.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    ['3714'],\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
