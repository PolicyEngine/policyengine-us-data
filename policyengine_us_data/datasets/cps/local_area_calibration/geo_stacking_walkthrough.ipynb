{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo-Stacking Calibration Walkthrough\n",
    "\n",
    "This notebook validates the sparse matrix construction and dataset creation pipeline for CD-level calibration. It traces a single household through the system to verify correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Matrix Construction\n",
    "\n",
    "Build the sparse calibration matrix `X_sparse` where rows are targets and columns are (household × CD) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baogorek/envs/pe/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_LITE == False\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from policyengine_us import Microsimulation\n",
    "from policyengine_us_data.storage import STORAGE_FOLDER\n",
    "from policyengine_us_data.datasets.cps.geo_stacking_calibration.metrics_matrix_geo_stacking_sparse import (\n",
    "    SparseGeoStackingMatrixBuilder,\n",
    ")\n",
    "from policyengine_us_data.datasets.cps.geo_stacking_calibration.calibration_utils import (\n",
    "    create_target_groups,\n",
    ")\n",
    "from policyengine_us_data.datasets.cps.geo_stacking_calibration.household_tracer import HouseholdTracer\n",
    "from policyengine_us_data.datasets.cps.geo_stacking_calibration.create_sparse_cd_stacked import create_sparse_cd_stacked_dataset\n",
    "\n",
    "rng_ben = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = STORAGE_FOLDER / \"policy_data.db\"\n",
    "db_uri = f\"sqlite:///{db_path}\"\n",
    "builder = SparseGeoStackingMatrixBuilder(db_uri, time_period=2023)\n",
    "\n",
    "engine = create_engine(db_uri)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT sc.value as cd_geoid\n",
    "FROM strata s\n",
    "JOIN stratum_constraints sc ON s.stratum_id = sc.stratum_id\n",
    "WHERE s.stratum_group_id = 1\n",
    "  AND sc.constraint_variable = 'congressional_district_geoid'\n",
    "ORDER BY sc.value\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(query)).fetchall()\n",
    "    all_cd_geoids = [row[0] for row in result]\n",
    "\n",
    "cds_to_calibrate = all_cd_geoids\n",
    "dataset_uri = STORAGE_FOLDER / \"stratified_extended_cps_2023.h5\"\n",
    "sim = Microsimulation(dataset=str(dataset_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Target Groups ===\n",
      "\n",
      "National targets (each is a singleton group):\n",
      "  Group 0: alimony_expense = 12,554,181,166\n",
      "  Group 1: alimony_income = 12,554,181,166\n",
      "  Group 2: charitable_deduction = 63,061,583,407\n",
      "  Group 3: child_support_expense = 31,868,306,036\n",
      "  Group 4: child_support_received = 31,868,306,036\n",
      "  Group 5: eitc = 64,440,000,000\n",
      "  Group 6: health_insurance_premiums_without_medicare_part_b = 371,796,903,749\n",
      "  Group 7: income_tax = 2,176,481,000,000\n",
      "  Group 8: interest_deduction = 23,949,514,839\n",
      "  Group 9: medicaid = 841,806,132,462\n",
      "  Group 10: medical_expense_deduction = 11,009,051,176\n",
      "  Group 11: medicare_part_b_premiums = 108,159,099,272\n",
      "  Group 12: net_worth = 154,512,998,960,600\n",
      "  Group 13: other_medical_expenses = 268,466,335,694\n",
      "  Group 14: over_the_counter_health_expenses = 71,220,353,850\n",
      "  Group 15: person_count_aca_ptc>0 = 19,529,896\n",
      "  Group 16: person_count_medicaid>0 = 71,644,763\n",
      "  Group 17: person_count_ssn_card_type=NONE = 12,200,000\n",
      "  Group 18: qualified_business_income_deduction = 60,936,063,965\n",
      "  Group 19: real_estate_taxes = 482,853,121,752\n",
      "  Group 20: rent = 709,794,088,975\n",
      "  Group 21: salt_deduction = 20,518,360,556\n",
      "  Group 22: snap = 107,062,860,000\n",
      "  Group 23: social_security = 1,379,268,000,000\n",
      "  Group 24: spm_unit_capped_housing_subsidy = 33,799,718,523\n",
      "  Group 25: spm_unit_capped_work_childcare_expenses = 336,065,772,739\n",
      "  Group 26: ssi = 60,090,000,000\n",
      "  Group 27: tanf = 8,691,356,192\n",
      "  Group 28: tip_income = 51,375,572,154\n",
      "  Group 29: unemployment_compensation = 35,000,000,000\n",
      "\n",
      "Geographic targets (grouped by variable type):\n",
      "  Group 30: All CD Age Distribution (7848 targets)\n",
      "  Group 31: All CD Person Income Distribution (3924 targets)\n",
      "  Group 32: All CD Medicaid Enrollment (436 targets)\n",
      "  Group 33: All CD Tax Units dividend_income>0 (436 targets)\n",
      "  Group 34: All CD Tax Units eitc_child_count==0 (436 targets)\n",
      "  Group 35: All CD Tax Units eitc_child_count==1 (436 targets)\n",
      "  Group 36: All CD Tax Units eitc_child_count==2 (436 targets)\n",
      "  Group 37: All CD Tax Units eitc_child_count>2 (436 targets)\n",
      "  Group 38: All CD Tax Units income_tax>0 (436 targets)\n",
      "  Group 39: All CD Tax Units income_tax_before_credits>0 (436 targets)\n",
      "  Group 40: All CD Tax Units medical_expense_deduction>0 (436 targets)\n",
      "  Group 41: All CD Tax Units net_capital_gains>0 (436 targets)\n",
      "  Group 42: All CD Tax Units qualified_business_income_deduction>0 (436 targets)\n",
      "  Group 43: All CD Tax Units qualified_dividend_income>0 (436 targets)\n",
      "  Group 44: All CD Tax Units real_estate_taxes>0 (436 targets)\n",
      "  Group 45: All CD Tax Units refundable_ctc>0 (436 targets)\n",
      "  Group 46: All CD Tax Units rental_income>0 (436 targets)\n",
      "  Group 47: All CD Tax Units salt>0 (436 targets)\n",
      "  Group 48: All CD Tax Units self_employment_income>0 (436 targets)\n",
      "  Group 49: All CD Tax Units tax_exempt_interest_income>0 (436 targets)\n",
      "  Group 50: All CD Tax Units tax_unit_partnership_s_corp_income>0 (436 targets)\n",
      "  Group 51: All CD Tax Units taxable_interest_income>0 (436 targets)\n",
      "  Group 52: All CD Tax Units taxable_ira_distributions>0 (436 targets)\n",
      "  Group 53: All CD Tax Units taxable_pension_income>0 (436 targets)\n",
      "  Group 54: All CD Tax Units taxable_social_security>0 (436 targets)\n",
      "  Group 55: All CD Tax Units unemployment_compensation>0 (436 targets)\n",
      "  Group 56: All CD AGI Total Amount (436 targets)\n",
      "  Group 57: All CD Dividend Income (436 targets)\n",
      "  Group 58: All CD Eitc (1744 targets)\n",
      "  Group 59: All CD SNAP Household Count (436 targets)\n",
      "  Group 60: All CD Income Tax (436 targets)\n",
      "  Group 61: All CD Income Tax Before Credits (436 targets)\n",
      "  Group 62: All CD Medical Expense Deduction (436 targets)\n",
      "  Group 63: All CD Net Capital Gains (436 targets)\n",
      "  Group 64: All CD Qualified Business Income Deduction (436 targets)\n",
      "  Group 65: All CD Qualified Dividend Income (436 targets)\n",
      "  Group 66: All CD Real Estate Taxes (436 targets)\n",
      "  Group 67: All CD Refundable Ctc (436 targets)\n",
      "  Group 68: All CD Rental Income (436 targets)\n",
      "  Group 69: All CD Salt (436 targets)\n",
      "  Group 70: All CD Self Employment Income (436 targets)\n",
      "  Group 71: State-level SNAP Cost (State) (51 targets)\n",
      "  Group 72: All CD Tax Exempt Interest Income (436 targets)\n",
      "  Group 73: All CD Tax Unit Partnership S Corp Income (436 targets)\n",
      "  Group 74: All CD Taxable Interest Income (436 targets)\n",
      "  Group 75: All CD Taxable Ira Distributions (436 targets)\n",
      "  Group 76: All CD Taxable Pension Income (436 targets)\n",
      "  Group 77: All CD Taxable Social Security (436 targets)\n",
      "  Group 78: All CD Unemployment Compensation (436 targets)\n",
      "\n",
      "Total groups created: 79\n",
      "========================================\n",
      "X_sparse shape: (33217, 5889488)\n",
      "Number of target groups: 79\n"
     ]
    }
   ],
   "source": [
    "targets_df, X_sparse, household_id_mapping = (\n",
    "    builder.build_stacked_matrix_sparse(\n",
    "        \"congressional_district\", cds_to_calibrate, sim\n",
    "    )\n",
    ")\n",
    "\n",
    "target_groups, group_info = create_target_groups(targets_df)\n",
    "tracer = HouseholdTracer(targets_df, X_sparse, household_id_mapping, cds_to_calibrate, sim)\n",
    "\n",
    "print(f\"X_sparse shape: {X_sparse.shape}\")\n",
    "print(f\"Number of target groups: {len(set(target_groups))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Understanding the Row Catalog\n",
    "\n",
    "The tracer provides a catalog of what each row (target) represents. We'll examine Group 71: SNAP Cost (State) - 51 targets across 51 states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MATRIX STRUCTURE BREAKDOWN\n",
      "================================================================================\n",
      "\n",
      "Matrix dimensions: 33217 rows × 5889488 columns\n",
      "  Rows = 33217 targets\n",
      "  Columns = 13508 households × 436 CDs\n",
      "           = 13,508 × 436 = 5,889,488\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "COLUMN STRUCTURE (Households stacked by CD)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Showing first and last 10 CDs of 436 total:\n",
      "\n",
      "First 10 CDs:\n",
      "cd_geoid  start_col  end_col  n_households  example_household_id\n",
      "    1001          0    13507         13508                    25\n",
      "     101      13508    27015         13508                    25\n",
      "     102      27016    40523         13508                    25\n",
      "     103      40524    54031         13508                    25\n",
      "     104      54032    67539         13508                    25\n",
      "     105      67540    81047         13508                    25\n",
      "     106      81048    94555         13508                    25\n",
      "     107      94556   108063         13508                    25\n",
      "    1101     108064   121571         13508                    25\n",
      "    1201     121572   135079         13508                    25\n",
      "\n",
      "Last 10 CDs:\n",
      "cd_geoid  start_col  end_col  n_households  example_household_id\n",
      "     804    5754408  5767915         13508                    25\n",
      "     805    5767916  5781423         13508                    25\n",
      "     806    5781424  5794931         13508                    25\n",
      "     807    5794932  5808439         13508                    25\n",
      "     808    5808440  5821947         13508                    25\n",
      "     901    5821948  5835455         13508                    25\n",
      "     902    5835456  5848963         13508                    25\n",
      "     903    5848964  5862471         13508                    25\n",
      "     904    5862472  5875979         13508                    25\n",
      "     905    5875980  5889487         13508                    25\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ROW STRUCTURE (Targets by geography and variable)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Targets by geographic level:\n",
      "geographic_level  n_targets\n",
      "         unknown      33217\n",
      "\n",
      "Targets by stratum group:\n",
      "                  n_targets  n_unique_vars\n",
      "stratum_group_id                          \n",
      "2                      8284              2\n",
      "3                      3924              1\n",
      "4                       436              1\n",
      "5                       436              1\n",
      "6                      3488              2\n",
      "100                     872              2\n",
      "101                     872              2\n",
      "102                     872              2\n",
      "103                     872              2\n",
      "104                     872              2\n",
      "105                     872              2\n",
      "106                     872              2\n",
      "107                     872              2\n",
      "108                     872              2\n",
      "109                     872              2\n",
      "110                     872              2\n",
      "111                     872              2\n",
      "112                     872              2\n",
      "113                     872              2\n",
      "114                     872              2\n",
      "115                     872              2\n",
      "116                     872              2\n",
      "117                     872              2\n",
      "118                     872              2\n",
      "national                 30             28\n",
      "state_snap_cost          51              1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TARGET GROUPS (for loss calculation)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== Creating Target Groups ===\n",
      "\n",
      "National targets (each is a singleton group):\n",
      "  Group 0: alimony_expense = 12,554,181,166\n",
      "  Group 1: alimony_income = 12,554,181,166\n",
      "  Group 2: charitable_deduction = 63,061,583,407\n",
      "  Group 3: child_support_expense = 31,868,306,036\n",
      "  Group 4: child_support_received = 31,868,306,036\n",
      "  Group 5: eitc = 64,440,000,000\n",
      "  Group 6: health_insurance_premiums_without_medicare_part_b = 371,796,903,749\n",
      "  Group 7: income_tax = 2,176,481,000,000\n",
      "  Group 8: interest_deduction = 23,949,514,839\n",
      "  Group 9: medicaid = 841,806,132,462\n",
      "  Group 10: medical_expense_deduction = 11,009,051,176\n",
      "  Group 11: medicare_part_b_premiums = 108,159,099,272\n",
      "  Group 12: net_worth = 154,512,998,960,600\n",
      "  Group 13: other_medical_expenses = 268,466,335,694\n",
      "  Group 14: over_the_counter_health_expenses = 71,220,353,850\n",
      "  Group 15: person_count_aca_ptc>0 = 19,529,896\n",
      "  Group 16: person_count_medicaid>0 = 71,644,763\n",
      "  Group 17: person_count_ssn_card_type=NONE = 12,200,000\n",
      "  Group 18: qualified_business_income_deduction = 60,936,063,965\n",
      "  Group 19: real_estate_taxes = 482,853,121,752\n",
      "  Group 20: rent = 709,794,088,975\n",
      "  Group 21: salt_deduction = 20,518,360,556\n",
      "  Group 22: snap = 107,062,860,000\n",
      "  Group 23: social_security = 1,379,268,000,000\n",
      "  Group 24: spm_unit_capped_housing_subsidy = 33,799,718,523\n",
      "  Group 25: spm_unit_capped_work_childcare_expenses = 336,065,772,739\n",
      "  Group 26: ssi = 60,090,000,000\n",
      "  Group 27: tanf = 8,691,356,192\n",
      "  Group 28: tip_income = 51,375,572,154\n",
      "  Group 29: unemployment_compensation = 35,000,000,000\n",
      "\n",
      "Geographic targets (grouped by variable type):\n",
      "  Group 30: All CD Age Distribution (7848 targets)\n",
      "  Group 31: All CD Person Income Distribution (3924 targets)\n",
      "  Group 32: All CD Medicaid Enrollment (436 targets)\n",
      "  Group 33: All CD Tax Units dividend_income>0 (436 targets)\n",
      "  Group 34: All CD Tax Units eitc_child_count==0 (436 targets)\n",
      "  Group 35: All CD Tax Units eitc_child_count==1 (436 targets)\n",
      "  Group 36: All CD Tax Units eitc_child_count==2 (436 targets)\n",
      "  Group 37: All CD Tax Units eitc_child_count>2 (436 targets)\n",
      "  Group 38: All CD Tax Units income_tax>0 (436 targets)\n",
      "  Group 39: All CD Tax Units income_tax_before_credits>0 (436 targets)\n",
      "  Group 40: All CD Tax Units medical_expense_deduction>0 (436 targets)\n",
      "  Group 41: All CD Tax Units net_capital_gains>0 (436 targets)\n",
      "  Group 42: All CD Tax Units qualified_business_income_deduction>0 (436 targets)\n",
      "  Group 43: All CD Tax Units qualified_dividend_income>0 (436 targets)\n",
      "  Group 44: All CD Tax Units real_estate_taxes>0 (436 targets)\n",
      "  Group 45: All CD Tax Units refundable_ctc>0 (436 targets)\n",
      "  Group 46: All CD Tax Units rental_income>0 (436 targets)\n",
      "  Group 47: All CD Tax Units salt>0 (436 targets)\n",
      "  Group 48: All CD Tax Units self_employment_income>0 (436 targets)\n",
      "  Group 49: All CD Tax Units tax_exempt_interest_income>0 (436 targets)\n",
      "  Group 50: All CD Tax Units tax_unit_partnership_s_corp_income>0 (436 targets)\n",
      "  Group 51: All CD Tax Units taxable_interest_income>0 (436 targets)\n",
      "  Group 52: All CD Tax Units taxable_ira_distributions>0 (436 targets)\n",
      "  Group 53: All CD Tax Units taxable_pension_income>0 (436 targets)\n",
      "  Group 54: All CD Tax Units taxable_social_security>0 (436 targets)\n",
      "  Group 55: All CD Tax Units unemployment_compensation>0 (436 targets)\n",
      "  Group 56: All CD AGI Total Amount (436 targets)\n",
      "  Group 57: All CD Dividend Income (436 targets)\n",
      "  Group 58: All CD Eitc (1744 targets)\n",
      "  Group 59: All CD SNAP Household Count (436 targets)\n",
      "  Group 60: All CD Income Tax (436 targets)\n",
      "  Group 61: All CD Income Tax Before Credits (436 targets)\n",
      "  Group 62: All CD Medical Expense Deduction (436 targets)\n",
      "  Group 63: All CD Net Capital Gains (436 targets)\n",
      "  Group 64: All CD Qualified Business Income Deduction (436 targets)\n",
      "  Group 65: All CD Qualified Dividend Income (436 targets)\n",
      "  Group 66: All CD Real Estate Taxes (436 targets)\n",
      "  Group 67: All CD Refundable Ctc (436 targets)\n",
      "  Group 68: All CD Rental Income (436 targets)\n",
      "  Group 69: All CD Salt (436 targets)\n",
      "  Group 70: All CD Self Employment Income (436 targets)\n",
      "  Group 71: State-level SNAP Cost (State) (51 targets)\n",
      "  Group 72: All CD Tax Exempt Interest Income (436 targets)\n",
      "  Group 73: All CD Tax Unit Partnership S Corp Income (436 targets)\n",
      "  Group 74: All CD Taxable Interest Income (436 targets)\n",
      "  Group 75: All CD Taxable Ira Distributions (436 targets)\n",
      "  Group 76: All CD Taxable Pension Income (436 targets)\n",
      "  Group 77: All CD Taxable Social Security (436 targets)\n",
      "  Group 78: All CD Unemployment Compensation (436 targets)\n",
      "\n",
      "Total groups created: 79\n",
      "========================================\n",
      "  Group 0: National alimony_expense (1 target, value=12,554,181,166) - rows [0]\n",
      "  Group 1: National alimony_income (1 target, value=12,554,181,166) - rows [1]\n",
      "  Group 2: National charitable_deduction (1 target, value=63,061,583,407) - rows [2]\n",
      "  Group 3: National child_support_expense (1 target, value=31,868,306,036) - rows [3]\n",
      "  Group 4: National child_support_received (1 target, value=31,868,306,036) - rows [4]\n",
      "  Group 5: National eitc (1 target, value=64,440,000,000) - rows [5]\n",
      "  Group 6: National health_insurance_premiums_without_medicare_part_b (1 target, value=371,796,903,749) - rows [6]\n",
      "  Group 7: National income_tax (1 target, value=2,176,481,000,000) - rows [7]\n",
      "  Group 8: National interest_deduction (1 target, value=23,949,514,839) - rows [8]\n",
      "  Group 9: National medicaid (1 target, value=841,806,132,462) - rows [9]\n",
      "  Group 10: National medical_expense_deduction (1 target, value=11,009,051,176) - rows [10]\n",
      "  Group 11: National medicare_part_b_premiums (1 target, value=108,159,099,272) - rows [11]\n",
      "  Group 12: National net_worth (1 target, value=154,512,998,960,600) - rows [12]\n",
      "  Group 13: National other_medical_expenses (1 target, value=268,466,335,694) - rows [13]\n",
      "  Group 14: National over_the_counter_health_expenses (1 target, value=71,220,353,850) - rows [14]\n",
      "  Group 15: National person_count_aca_ptc>0 (1 target, value=19,529,896) - rows [15]\n",
      "  Group 16: National person_count_medicaid>0 (1 target, value=71,644,763) - rows [16]\n",
      "  Group 17: National person_count_ssn_card_type=NONE (1 target, value=12,200,000) - rows [17]\n",
      "  Group 18: National qualified_business_income_deduction (1 target, value=60,936,063,965) - rows [18]\n",
      "  Group 19: National real_estate_taxes (1 target, value=482,853,121,752) - rows [19]\n",
      "  Group 20: National rent (1 target, value=709,794,088,975) - rows [20]\n",
      "  Group 21: National salt_deduction (1 target, value=20,518,360,556) - rows [21]\n",
      "  Group 22: National snap (1 target, value=107,062,860,000) - rows [22]\n",
      "  Group 23: National social_security (1 target, value=1,379,268,000,000) - rows [23]\n",
      "  Group 24: National spm_unit_capped_housing_subsidy (1 target, value=33,799,718,523) - rows [24]\n",
      "  Group 25: National spm_unit_capped_work_childcare_expenses (1 target, value=336,065,772,739) - rows [25]\n",
      "  Group 26: National ssi (1 target, value=60,090,000,000) - rows [26]\n",
      "  Group 27: National tanf (1 target, value=8,691,356,192) - rows [27]\n",
      "  Group 28: National tip_income (1 target, value=51,375,572,154) - rows [28]\n",
      "  Group 29: National unemployment_compensation (1 target, value=35,000,000,000) - rows [29]\n",
      "  Group 30: Age Distribution (7848 targets across 436 geographies) - rows [50, 51, 52, '...', 33126, 33127]\n",
      "  Group 31: Person Income Distribution (3924 targets across 436 geographies) - rows [41, 42, 43, '...', 33108, 33109]\n",
      "  Group 32: Medicaid Enrollment (436 targets across 436 geographies) - rows [68, 144, 220, '...', 33052, 33128]\n",
      "  Group 33: Tax Units dividend_income>0 (436 targets across 436 geographies) - rows [77, 153, 229, '...', 33061, 33137]\n",
      "  Group 34: Tax Units eitc_child_count==0 (436 targets across 436 geographies) - rows [78, 154, 230, '...', 33062, 33138]\n",
      "  Group 35: Tax Units eitc_child_count==1 (436 targets across 436 geographies) - rows [79, 155, 231, '...', 33063, 33139]\n",
      "  Group 36: Tax Units eitc_child_count==2 (436 targets across 436 geographies) - rows [80, 156, 232, '...', 33064, 33140]\n",
      "  Group 37: Tax Units eitc_child_count>2 (436 targets across 436 geographies) - rows [81, 157, 233, '...', 33065, 33141]\n",
      "  Group 38: Tax Units income_tax>0 (436 targets across 436 geographies) - rows [83, 159, 235, '...', 33067, 33143]\n",
      "  Group 39: Tax Units income_tax_before_credits>0 (436 targets across 436 geographies) - rows [82, 158, 234, '...', 33066, 33142]\n",
      "  Group 40: Tax Units medical_expense_deduction>0 (436 targets across 436 geographies) - rows [84, 160, 236, '...', 33068, 33144]\n",
      "  Group 41: Tax Units net_capital_gains>0 (436 targets across 436 geographies) - rows [85, 161, 237, '...', 33069, 33145]\n",
      "  Group 42: Tax Units qualified_business_income_deduction>0 (436 targets across 436 geographies) - rows [86, 162, 238, '...', 33070, 33146]\n",
      "  Group 43: Tax Units qualified_dividend_income>0 (436 targets across 436 geographies) - rows [87, 163, 239, '...', 33071, 33147]\n",
      "  Group 44: Tax Units real_estate_taxes>0 (436 targets across 436 geographies) - rows [88, 164, 240, '...', 33072, 33148]\n",
      "  Group 45: Tax Units refundable_ctc>0 (436 targets across 436 geographies) - rows [89, 165, 241, '...', 33073, 33149]\n",
      "  Group 46: Tax Units rental_income>0 (436 targets across 436 geographies) - rows [90, 166, 242, '...', 33074, 33150]\n",
      "  Group 47: Tax Units salt>0 (436 targets across 436 geographies) - rows [91, 167, 243, '...', 33075, 33151]\n",
      "  Group 48: Tax Units self_employment_income>0 (436 targets across 436 geographies) - rows [92, 168, 244, '...', 33076, 33152]\n",
      "  Group 49: Tax Units tax_exempt_interest_income>0 (436 targets across 436 geographies) - rows [93, 169, 245, '...', 33077, 33153]\n",
      "  Group 50: Tax Units tax_unit_partnership_s_corp_income>0 (436 targets across 436 geographies) - rows [94, 170, 246, '...', 33078, 33154]\n",
      "  Group 51: Tax Units taxable_interest_income>0 (436 targets across 436 geographies) - rows [95, 171, 247, '...', 33079, 33155]\n",
      "  Group 52: Tax Units taxable_ira_distributions>0 (436 targets across 436 geographies) - rows [96, 172, 248, '...', 33080, 33156]\n",
      "  Group 53: Tax Units taxable_pension_income>0 (436 targets across 436 geographies) - rows [97, 173, 249, '...', 33081, 33157]\n",
      "  Group 54: Tax Units taxable_social_security>0 (436 targets across 436 geographies) - rows [98, 174, 250, '...', 33082, 33158]\n",
      "  Group 55: Tax Units unemployment_compensation>0 (436 targets across 436 geographies) - rows [99, 175, 251, '...', 33083, 33159]\n",
      "  Group 56: AGI Total Amount (436 targets across 436 geographies) - rows [30, 106, 182, '...', 33014, 33090]\n",
      "  Group 57: Dividend Income (436 targets across 436 geographies) - rows [31, 107, 183, '...', 33015, 33091]\n",
      "  Group 58: Eitc (1744 targets across 436 geographies) - rows [32, 33, 34, '...', 33094, 33095]\n",
      "  Group 59: SNAP Household Count (436 targets across 436 geographies) - rows [36, 112, 188, '...', 33020, 33096]\n",
      "  Group 60: Income Tax (436 targets across 436 geographies) - rows [38, 114, 190, '...', 33022, 33098]\n",
      "  Group 61: Income Tax Before Credits (436 targets across 436 geographies) - rows [37, 113, 189, '...', 33021, 33097]\n",
      "  Group 62: Medical Expense Deduction (436 targets across 436 geographies) - rows [39, 115, 191, '...', 33023, 33099]\n",
      "  Group 63: Net Capital Gains (436 targets across 436 geographies) - rows [40, 116, 192, '...', 33024, 33100]\n",
      "  Group 64: Qualified Business Income Deduction (436 targets across 436 geographies) - rows [69, 145, 221, '...', 33053, 33129]\n",
      "  Group 65: Qualified Dividend Income (436 targets across 436 geographies) - rows [70, 146, 222, '...', 33054, 33130]\n",
      "  Group 66: Real Estate Taxes (436 targets across 436 geographies) - rows [71, 147, 223, '...', 33055, 33131]\n",
      "  Group 67: Refundable Ctc (436 targets across 436 geographies) - rows [72, 148, 224, '...', 33056, 33132]\n",
      "  Group 68: Rental Income (436 targets across 436 geographies) - rows [73, 149, 225, '...', 33057, 33133]\n",
      "  Group 69: Salt (436 targets across 436 geographies) - rows [74, 150, 226, '...', 33058, 33134]\n",
      "  Group 70: Self Employment Income (436 targets across 436 geographies) - rows [75, 151, 227, '...', 33059, 33135]\n",
      "  Group 71: SNAP Cost (State) (51 targets across 51 geographies) - rows [33166, 33167, 33168, '...', 33215, 33216]\n",
      "  Group 72: Tax Exempt Interest Income (436 targets across 436 geographies) - rows [76, 152, 228, '...', 33060, 33136]\n",
      "  Group 73: Tax Unit Partnership S Corp Income (436 targets across 436 geographies) - rows [100, 176, 252, '...', 33084, 33160]\n",
      "  Group 74: Taxable Interest Income (436 targets across 436 geographies) - rows [101, 177, 253, '...', 33085, 33161]\n",
      "  Group 75: Taxable Ira Distributions (436 targets across 436 geographies) - rows [102, 178, 254, '...', 33086, 33162]\n",
      "  Group 76: Taxable Pension Income (436 targets across 436 geographies) - rows [103, 179, 255, '...', 33087, 33163]\n",
      "  Group 77: Taxable Social Security (436 targets across 436 geographies) - rows [104, 180, 256, '...', 33088, 33164]\n",
      "  Group 78: Unemployment Compensation (436 targets across 436 geographies) - rows [105, 181, 257, '...', 33089, 33165]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "tracer.print_matrix_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row info for first SNAP state target:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'row_index': 33194,\n",
       " 'variable': 'snap',\n",
       " 'variable_desc': 'snap_cost_state',\n",
       " 'geographic_id': '37',\n",
       " 'geographic_level': 'unknown',\n",
       " 'target_value': 4041086120.0,\n",
       " 'stratum_id': 9799,\n",
       " 'stratum_group_id': 'state_snap_cost'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_71 = tracer.get_group_rows(71)\n",
    "row_loc = group_71.iloc[28]['row_index']\n",
    "row_info = tracer.get_row_info(row_loc)\n",
    "var = row_info['variable']\n",
    "var_desc = row_info['variable_desc']\n",
    "target_geo_id = int(row_info['geographic_id'])\n",
    "\n",
    "print(\"Row info for first SNAP state target:\")\n",
    "row_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>variable</th>\n",
       "      <th>variable_desc</th>\n",
       "      <th>geographic_id</th>\n",
       "      <th>geographic_level</th>\n",
       "      <th>target_value</th>\n",
       "      <th>stratum_id</th>\n",
       "      <th>stratum_group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33166</th>\n",
       "      <td>33166</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2.048985e+09</td>\n",
       "      <td>9766</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33167</th>\n",
       "      <td>33167</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>10</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2.962075e+08</td>\n",
       "      <td>9773</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33168</th>\n",
       "      <td>33168</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>11</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3.793723e+08</td>\n",
       "      <td>9774</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33169</th>\n",
       "      <td>33169</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>6.756577e+09</td>\n",
       "      <td>9775</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33170</th>\n",
       "      <td>33170</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>13</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3.232508e+09</td>\n",
       "      <td>9776</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33171</th>\n",
       "      <td>33171</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>15</td>\n",
       "      <td>unknown</td>\n",
       "      <td>8.424059e+08</td>\n",
       "      <td>9777</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33172</th>\n",
       "      <td>33172</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2.494227e+08</td>\n",
       "      <td>9778</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33173</th>\n",
       "      <td>33173</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>17</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.440580e+09</td>\n",
       "      <td>9779</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33174</th>\n",
       "      <td>33174</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>18</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1.302143e+09</td>\n",
       "      <td>9780</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33175</th>\n",
       "      <td>33175</td>\n",
       "      <td>snap</td>\n",
       "      <td>snap_cost_state</td>\n",
       "      <td>19</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.091406e+08</td>\n",
       "      <td>9781</td>\n",
       "      <td>state_snap_cost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_index variable    variable_desc geographic_id geographic_level  \\\n",
       "33166      33166     snap  snap_cost_state             1          unknown   \n",
       "33167      33167     snap  snap_cost_state            10          unknown   \n",
       "33168      33168     snap  snap_cost_state            11          unknown   \n",
       "33169      33169     snap  snap_cost_state            12          unknown   \n",
       "33170      33170     snap  snap_cost_state            13          unknown   \n",
       "33171      33171     snap  snap_cost_state            15          unknown   \n",
       "33172      33172     snap  snap_cost_state            16          unknown   \n",
       "33173      33173     snap  snap_cost_state            17          unknown   \n",
       "33174      33174     snap  snap_cost_state            18          unknown   \n",
       "33175      33175     snap  snap_cost_state            19          unknown   \n",
       "\n",
       "       target_value  stratum_id stratum_group_id  \n",
       "33166  2.048985e+09        9766  state_snap_cost  \n",
       "33167  2.962075e+08        9773  state_snap_cost  \n",
       "33168  3.793723e+08        9774  state_snap_cost  \n",
       "33169  6.756577e+09        9775  state_snap_cost  \n",
       "33170  3.232508e+09        9776  state_snap_cost  \n",
       "33171  8.424059e+08        9777  state_snap_cost  \n",
       "33172  2.494227e+08        9778  state_snap_cost  \n",
       "33173  5.440580e+09        9779  state_snap_cost  \n",
       "33174  1.302143e+09        9780  state_snap_cost  \n",
       "33175  5.091406e+08        9781  state_snap_cost  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_snap = tracer.row_catalog[\n",
    "    (tracer.row_catalog['variable'] == row_info['variable']) &\n",
    "    (tracer.row_catalog['variable_desc'] == row_info['variable_desc'])\n",
    "].sort_values('geographic_id')\n",
    "\n",
    "assert state_snap.shape[0] == 51, f\"Expected 51 state SNAP targets, got {state_snap.shape[0]}\"\n",
    "state_snap.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Finding an Interesting Household\n",
    "\n",
    "We need a household with:\n",
    "- More than one person\n",
    "- More than one SPM unit\n",
    "- Each SPM unit has positive SNAP\n",
    "\n",
    "This tests that we correctly aggregate SNAP at the household level (sum across SPM units, not persons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>household_id</th>\n",
       "      <th>tax_unit_id</th>\n",
       "      <th>spm_unit_id</th>\n",
       "      <th>family_id</th>\n",
       "      <th>marital_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2501</td>\n",
       "      <td>25</td>\n",
       "      <td>2501</td>\n",
       "      <td>25001</td>\n",
       "      <td>251.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10301</td>\n",
       "      <td>103</td>\n",
       "      <td>10301</td>\n",
       "      <td>103001</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12501</td>\n",
       "      <td>125</td>\n",
       "      <td>12501</td>\n",
       "      <td>125001</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12502</td>\n",
       "      <td>125</td>\n",
       "      <td>12501</td>\n",
       "      <td>125001</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12503</td>\n",
       "      <td>125</td>\n",
       "      <td>12502</td>\n",
       "      <td>125001</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  household_id  tax_unit_id  spm_unit_id  family_id  \\\n",
       "0       2501            25         2501        25001      251.0   \n",
       "1      10301           103        10301       103001     1031.0   \n",
       "2      12501           125        12501       125001     1251.0   \n",
       "3      12502           125        12501       125001     1251.0   \n",
       "4      12503           125        12502       125001     1252.0   \n",
       "\n",
       "   marital_unit_id  \n",
       "0               20  \n",
       "1               80  \n",
       "2               99  \n",
       "3              101  \n",
       "4              100  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_rel = pd.DataFrame(\n",
    "    {\n",
    "        \"person_id\": sim.calculate(\"person_id\", map_to=\"person\").values,\n",
    "        \"household_id\": sim.calculate(\"household_id\", map_to=\"person\").values,\n",
    "        \"tax_unit_id\": sim.calculate(\"tax_unit_id\", map_to=\"person\").values,\n",
    "        \"spm_unit_id\": sim.calculate(\"spm_unit_id\", map_to=\"person\").values,\n",
    "        \"family_id\": sim.calculate(\"family_id\", map_to=\"person\").values,\n",
    "        \"marital_unit_id\": sim.calculate(\"marital_unit_id\", map_to=\"person\").values,\n",
    "    }\n",
    ")\n",
    "entity_rel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: SNAP values differ by entity level due to broadcasting:\n",
    "- `sim.calculate_dataframe(['spm_unit_id', 'snap'])` - rows are SPM units\n",
    "- `sim.calculate_dataframe(['household_id', 'snap'])` - rows are households\n",
    "- Person-level broadcasts the SPM unit's SNAP to each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_household_id</th>\n",
       "      <th>person_count</th>\n",
       "      <th>snap_min</th>\n",
       "      <th>snap_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>66231</td>\n",
       "      <td>2</td>\n",
       "      <td>2293.199951</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>80662</td>\n",
       "      <td>2</td>\n",
       "      <td>937.499756</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>82168</td>\n",
       "      <td>3</td>\n",
       "      <td>789.199951</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6683</th>\n",
       "      <td>91997</td>\n",
       "      <td>3</td>\n",
       "      <td>3592.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>97972</td>\n",
       "      <td>2</td>\n",
       "      <td>789.199951</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>112528</td>\n",
       "      <td>2</td>\n",
       "      <td>3236.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>128839</td>\n",
       "      <td>3</td>\n",
       "      <td>789.199951</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      person_household_id  person_count     snap_min  snap_unique\n",
       "4592                66231             2  2293.199951            2\n",
       "5672                80662             2   937.499756            2\n",
       "5804                82168             3   789.199951            3\n",
       "6683                91997             3  3592.000000            2\n",
       "7143                97972             2   789.199951            2\n",
       "8340               112528             2  3236.500000            2\n",
       "9491               128839             3   789.199951            2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_df = sim.calculate_dataframe(['person_household_id', 'person_id', 'snap'], map_to=\"person\")\n",
    "\n",
    "hh_stats = p_df.groupby('person_household_id').agg(\n",
    "    person_count=('person_id', 'nunique'),\n",
    "    snap_min=('snap', 'min'),\n",
    "    snap_unique=('snap', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "candidates = hh_stats[(hh_stats.person_count > 1) & (hh_stats.snap_min > 0) & (hh_stats.snap_unique > 1)]\n",
    "candidates.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_household_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>snap</th>\n",
       "      <th>__tmp_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19739</th>\n",
       "      <td>91997</td>\n",
       "      <td>9199706</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19740</th>\n",
       "      <td>91997</td>\n",
       "      <td>9199707</td>\n",
       "      <td>4333.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19741</th>\n",
       "      <td>91997</td>\n",
       "      <td>9199708</td>\n",
       "      <td>4333.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight  person_household_id  person_id    snap  __tmp_weights\n",
       "19739     0.0                91997    9199706  3592.0            0.0\n",
       "19740     0.0                91997    9199707  4333.5            0.0\n",
       "19741     0.0                91997    9199708  4333.5            0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_id = candidates.iloc[3]['person_household_id']\n",
    "p_df.loc[p_df.person_household_id == hh_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This household has 3 persons across 2 SPM units:\n",
    "- Person 1, 2: SNAP = 3592.0\n",
    "- Persons 3: SNAP = 789.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spm_unit_id</th>\n",
       "      <th>snap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>91997002</td>\n",
       "      <td>3592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>91997004</td>\n",
       "      <td>4333.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      weight  spm_unit_id    snap\n",
       "6989     0.0     91997002  3592.0\n",
       "6990     0.0     91997004  4333.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_snap_goal = 3592.0 + 4333.5\n",
    "\n",
    "snap_df = sim.calculate_dataframe(['spm_unit_id', 'snap'])\n",
    "snap_subset = entity_rel.loc[entity_rel.household_id == hh_id]\n",
    "snap_df.loc[snap_df.spm_unit_id.isin(list(snap_subset.spm_unit_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Household 91997.0 is from state FIPS 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "household_id    91997\n",
       "state_fips         50\n",
       "Name: 6683, dtype: int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_df = sim.calculate_dataframe(['household_id', 'state_fips'])\n",
    "hh_loc = np.where(hh_df.household_id == hh_id)[0][0]\n",
    "hh_one = hh_df.iloc[hh_loc]\n",
    "hh_home_state = hh_one.state_fips\n",
    "\n",
    "print(f\"Household {hh_id} is from state FIPS {hh_home_state}\")\n",
    "hh_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Validate Matrix Values\n",
    "\n",
    "Each household appears as a column in X_sparse for every CD (436 times). For state-level SNAP targets, the matrix value should be:\n",
    "- `hh_snap_goal` if the CD is in the household's home state\n",
    "- `0` if the CD is in a different state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 436 CD column values validated for household 91997.0\n"
     ]
    }
   ],
   "source": [
    "hh_col_lku = tracer.get_household_column_positions(hh_id)\n",
    "\n",
    "for cd in hh_col_lku.keys():\n",
    "    hh_away_state = int(cd) // 100\n",
    "    col_loc = hh_col_lku[cd]\n",
    "    col_info = tracer.get_column_info(col_loc)\n",
    "    \n",
    "    assert col_info['household_id'] == hh_id\n",
    "    \n",
    "    value_lku = tracer.lookup_matrix_cell(row_idx=row_loc, col_idx=col_loc)\n",
    "    assert value_lku['household']['household_id'] == hh_id\n",
    "    \n",
    "    metric = value_lku['matrix_value']\n",
    "    assert X_sparse[row_loc, col_loc] == metric\n",
    "\n",
    "    if hh_away_state != target_geo_id:\n",
    "        assert metric == 0, f\"Expected 0 for CD {cd} (state {hh_away_state}), got {metric}\"\n",
    "    else:\n",
    "        assert metric == hh_snap_goal, f\"Expected {hh_snap_goal} for CD {cd}, got {metric}\"\n",
    "\n",
    "print(f\"All {len(hh_col_lku)} CD column values validated for household {hh_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Create Sparse Dataset from Weights\n",
    "\n",
    "Test `create_sparse_cd_stacked_dataset` which reconstructs an h5 file from weight vectors. We verify:\n",
    "1. Household appears in mapping file for CDs with non-zero weight\n",
    "2. New household IDs correctly map back to originals\n",
    "3. SNAP values are preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nonzero = 500000\n",
    "total_size = X_sparse.shape[1]\n",
    "\n",
    "w = np.zeros(total_size)\n",
    "nonzero_indices = rng_ben.choice(total_size, n_nonzero, replace=False)\n",
    "w[nonzero_indices] = 2\n",
    "\n",
    "cd1 = '103'\n",
    "cd2 = '3703'\n",
    "output_dir = './temp'\n",
    "w[hh_col_lku[cd1]] = 1.5\n",
    "w[hh_col_lku[cd2]] = 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subset of 2 CDs: 103, 3703...\n",
      "Output path: ./temp/mapping1.h5\n",
      "\n",
      "Original dataset has 13,508 households\n",
      "Extracted weights for 2 CDs from full weight matrix\n",
      "Total active household-CD pairs: 2,292\n",
      "Total weight in W matrix: 4,583\n",
      "Processing CD 3703 (2/2)...\n",
      "\n",
      "Combining 2 CD DataFrames...\n",
      "Total households across all CDs: 2,292\n",
      "Combined DataFrame shape: (7054, 184)\n",
      "\n",
      "Weights in combined_df BEFORE reindexing:\n",
      "  HH weight sum: 0.01M\n",
      "  Person weight sum: 0.01M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Reindexing all entity IDs using 25k ranges per CD...\n",
      "  Created 2,292 unique households across 2 CDs\n",
      "  Reindexing persons using 25k ranges...\n",
      "  Reindexing tax units...\n",
      "  Reindexing SPM units...\n",
      "  Reindexing marital units...\n",
      "  Final persons: 7,054\n",
      "  Final households: 2,292\n",
      "  Final tax units: 3,252\n",
      "  Final SPM units: 2,412\n",
      "  Final marital units: 5,445\n",
      "\n",
      "Weights in combined_df AFTER reindexing:\n",
      "  HH weight sum: 0.01M\n",
      "  Person weight sum: 0.01M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Overflow check:\n",
      "  Max person ID after reindexing: 10,203,635\n",
      "  Max person ID × 100: 1,020,363,500\n",
      "  int32 max: 2,147,483,647\n",
      "  ✓ No overflow risk!\n",
      "\n",
      "Creating Dataset from combined DataFrame...\n",
      "Building simulation from Dataset...\n",
      "\n",
      "Saving to ./temp/mapping1.h5...\n",
      "Found 168 input variables (excluding calculated variables)\n",
      "Variables saved: 180\n",
      "Variables skipped: 3213\n",
      "Sparse CD-stacked dataset saved successfully!\n",
      "Household mapping saved to ./temp/mappings/mapping1_household_mapping.csv\n",
      "\n",
      "Verifying saved file...\n",
      "  Final households: 2,292\n",
      "  Final persons: 7,054\n",
      "  Total population (from household weights): 4,583\n",
      "  Total population (from person weights): 14,106\n",
      "  Average persons per household: 3.08\n",
      "Output dataset shape: (2292, 4)\n"
     ]
    }
   ],
   "source": [
    "output_path = f\"{output_dir}/mapping1.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    cds_to_calibrate,\n",
    "    cd_subset=[cd1, cd2],\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    ")\n",
    "\n",
    "sim_test = Microsimulation(dataset=output_path)\n",
    "df_test = sim_test.calculate_dataframe([\n",
    "    'congressional_district_geoid',\n",
    "    'household_id', 'household_weight', 'snap'])\n",
    "\n",
    "print(f\"Output dataset shape: {df_test.shape}\")\n",
    "assert np.isclose(df_test.shape[0] / 2 * 436, n_nonzero, rtol=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_household_id</th>\n",
       "      <th>original_household_id</th>\n",
       "      <th>congressional_district</th>\n",
       "      <th>state_fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>75572</td>\n",
       "      <td>91997</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>5200579</td>\n",
       "      <td>91997</td>\n",
       "      <td>3703</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      new_household_id  original_household_id  congressional_district  \\\n",
       "1151             75572                  91997                     103   \n",
       "1152           5200579                  91997                    3703   \n",
       "\n",
       "      state_fips  \n",
       "1151           1  \n",
       "1152          37  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.read_csv(f\"{output_dir}/mappings/mapping1_household_mapping.csv\")\n",
    "match = mapping.loc[mapping.original_household_id == hh_id].shape[0]\n",
    "assert match == 2, f\"Household should appear twice (once per CD), got {match}\"\n",
    "\n",
    "hh_mapping = mapping.loc[mapping.original_household_id == hh_id]\n",
    "hh_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congressional_district_geoid</th>\n",
       "      <th>household_id</th>\n",
       "      <th>household_weight</th>\n",
       "      <th>snap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>75000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103</td>\n",
       "      <td>75001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>75002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>75003</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>75004</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>3703</td>\n",
       "      <td>5201163</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>3703</td>\n",
       "      <td>5201164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>3703</td>\n",
       "      <td>5201165</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>3703</td>\n",
       "      <td>5201166</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>3703</td>\n",
       "      <td>5201167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2292 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      weight  congressional_district_geoid  household_id  household_weight  \\\n",
       "0        2.0                           103         75000               2.0   \n",
       "1        2.0                           103         75001               2.0   \n",
       "2        2.0                           103         75002               2.0   \n",
       "3        2.0                           103         75003               2.0   \n",
       "4        2.0                           103         75004               2.0   \n",
       "...      ...                           ...           ...               ...   \n",
       "2287     2.0                          3703       5201163               2.0   \n",
       "2288     2.0                          3703       5201164               2.0   \n",
       "2289     2.0                          3703       5201165               2.0   \n",
       "2290     2.0                          3703       5201166               2.0   \n",
       "2291     2.0                          3703       5201167               2.0   \n",
       "\n",
       "      snap  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "2287   0.0  \n",
       "2288   0.0  \n",
       "2289   0.0  \n",
       "2290   0.0  \n",
       "2291   0.0  \n",
       "\n",
       "[2292 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD 103: weight=1.5, snap=7925.5\n"
     ]
    }
   ],
   "source": [
    "df_test_cd1 = df_test.loc[df_test.congressional_district_geoid == int(cd1)]\n",
    "df_test_cd2 = df_test.loc[df_test.congressional_district_geoid == int(cd2)]\n",
    "\n",
    "hh_mapping_cd1 = hh_mapping.loc[hh_mapping.congressional_district == int(cd1)]\n",
    "new_hh_id_cd1 = hh_mapping_cd1['new_household_id'].values[0]\n",
    "\n",
    "assert hh_mapping_cd1.shape[0] == 1\n",
    "assert hh_mapping_cd1.original_household_id.values[0] == hh_id\n",
    "\n",
    "w_hh_cd1 = w[hh_col_lku[cd1]]\n",
    "assert_cd1_df = df_test_cd1.loc[df_test_cd1.household_id == new_hh_id_cd1]\n",
    "\n",
    "assert np.isclose(assert_cd1_df.household_weight.values[0], w_hh_cd1, atol=0.001)\n",
    "assert np.isclose(assert_cd1_df.snap.values[0], hh_snap_goal, atol=0.001)\n",
    "\n",
    "print(f\"CD {cd1}: weight={w_hh_cd1}, snap={assert_cd1_df.snap.values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD 3703: weight=1.7, snap=7925.5\n"
     ]
    }
   ],
   "source": [
    "hh_mapping_cd2 = hh_mapping.loc[hh_mapping.congressional_district == int(cd2)]\n",
    "new_hh_id_cd2 = hh_mapping_cd2['new_household_id'].values[0]\n",
    "\n",
    "assert hh_mapping_cd2.shape[0] == 1\n",
    "assert hh_mapping_cd2.original_household_id.values[0] == hh_id\n",
    "\n",
    "w_hh_cd2 = w[hh_col_lku[cd2]]\n",
    "assert_cd2_df = df_test_cd2.loc[df_test_cd2.household_id == new_hh_id_cd2]\n",
    "\n",
    "assert np.isclose(assert_cd2_df.household_weight.values[0], w_hh_cd2, atol=0.001)\n",
    "assert np.isclose(assert_cd2_df.snap.values[0], hh_snap_goal, atol=0.001)\n",
    "\n",
    "print(f\"CD {cd2}: weight={w_hh_cd2}, snap={assert_cd2_df.snap.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Zero weight excludes household from mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subset of 1 CDs: 3703...\n",
      "Output path: ./temp/3703.h5\n",
      "\n",
      "Original dataset has 13,508 households\n",
      "Extracted weights for 1 CDs from full weight matrix\n",
      "Total active household-CD pairs: 1,167\n",
      "Total weight in W matrix: 2,334\n",
      "Processing CD 3703 (1/1)...\n",
      "\n",
      "Combining 1 CD DataFrames...\n",
      "Total households across all CDs: 1,167\n",
      "Combined DataFrame shape: (3633, 184)\n",
      "\n",
      "Weights in combined_df BEFORE reindexing:\n",
      "  HH weight sum: 0.01M\n",
      "  Person weight sum: 0.01M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Reindexing all entity IDs using 25k ranges per CD...\n",
      "  Created 1,167 unique households across 1 CDs\n",
      "  Reindexing persons using 25k ranges...\n",
      "  Reindexing tax units...\n",
      "  Reindexing SPM units...\n",
      "  Reindexing marital units...\n",
      "  Final persons: 3,633\n",
      "  Final households: 1,167\n",
      "  Final tax units: 1,683\n",
      "  Final SPM units: 1,227\n",
      "  Final marital units: 2,818\n",
      "\n",
      "Weights in combined_df AFTER reindexing:\n",
      "  HH weight sum: 0.01M\n",
      "  Person weight sum: 0.01M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Overflow check:\n",
      "  Max person ID after reindexing: 10,203,632\n",
      "  Max person ID × 100: 1,020,363,200\n",
      "  int32 max: 2,147,483,647\n",
      "  ✓ No overflow risk!\n",
      "\n",
      "Creating Dataset from combined DataFrame...\n",
      "Building simulation from Dataset...\n",
      "\n",
      "Saving to ./temp/3703.h5...\n",
      "Found 168 input variables (excluding calculated variables)\n",
      "Variables saved: 180\n",
      "Variables skipped: 3213\n",
      "Sparse CD-stacked dataset saved successfully!\n",
      "Household mapping saved to ./temp/mappings/3703_household_mapping.csv\n",
      "\n",
      "Verifying saved file...\n",
      "  Final households: 1,167\n",
      "  Final persons: 3,633\n",
      "  Total population (from household weights): 2,334\n",
      "  Total population (from person weights): 7,266\n",
      "  Average persons per household: 3.11\n",
      "Confirmed: household 91997.0 excluded from CD 3703 mapping when weight=0\n"
     ]
    }
   ],
   "source": [
    "w[hh_col_lku[cd2]] = 0\n",
    "\n",
    "output_path = f\"{output_dir}/{cd2}.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    cds_to_calibrate,\n",
    "    cd_subset=[cd2],\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    ")\n",
    "\n",
    "sim_test = Microsimulation(dataset=output_path)\n",
    "df_test = sim_test.calculate_dataframe(['household_id', 'household_weight', 'snap'])\n",
    "\n",
    "cd2_mapping = pd.read_csv(f\"{output_dir}/mappings/{cd2}_household_mapping.csv\")\n",
    "match = cd2_mapping.loc[cd2_mapping.original_household_id == hh_id].shape[0]\n",
    "assert match == 0, f\"Household with zero weight should not appear in mapping, got {match}\"\n",
    "\n",
    "print(f\"Confirmed: household {hh_id} excluded from CD {cd2} mapping when weight=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: End-to-End Validation (X @ w == sim.calculate)\n",
    "\n",
    "The ultimate test: verify that matrix multiplication `X_sparse @ w` matches what we get from running the simulation on the reconstructed h5 file.\n",
    "\n",
    "With `freeze_calculated_vars=True`, state-dependent variables like SNAP are saved to the h5 file to prevent recalculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = X_sparse.shape[1]\n",
    "w = np.zeros(total_size)\n",
    "n_nonzero = 50000\n",
    "nonzero_indices = rng_ben.choice(total_size, n_nonzero, replace=False)\n",
    "w[nonzero_indices] = 7\n",
    "w[hh_col_lku[cd1]] = 11\n",
    "w[hh_col_lku[cd2]] = 12\n",
    "\n",
    "assert np.sum(w > 0) <= n_nonzero + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all 436 congressional districts\n",
      "Output path: ./temp/national.h5\n",
      "\n",
      "Original dataset has 13,508 households\n",
      "Total active household-CD pairs: 50,002\n",
      "Total weight in W matrix: 350,023\n",
      "Processing CD 1201 (10/436)...\n",
      "Processing CD 1211 (20/436)...\n",
      "Processing CD 1221 (30/436)...\n",
      "Processing CD 1303 (40/436)...\n",
      "Processing CD 1313 (50/436)...\n",
      "Processing CD 1705 (60/436)...\n",
      "Processing CD 1715 (70/436)...\n",
      "Processing CD 1808 (80/436)...\n",
      "Processing CD 201 (90/436)...\n",
      "Processing CD 2204 (100/436)...\n",
      "Processing CD 2406 (110/436)...\n",
      "Processing CD 2508 (120/436)...\n",
      "Processing CD 2609 (130/436)...\n",
      "Processing CD 2706 (140/436)...\n",
      "Processing CD 2904 (150/436)...\n",
      "Processing CD 3201 (160/436)...\n",
      "Processing CD 3405 (170/436)...\n",
      "Processing CD 3503 (180/436)...\n",
      "Processing CD 3610 (190/436)...\n",
      "Processing CD 3620 (200/436)...\n",
      "Processing CD 3704 (210/436)...\n",
      "Processing CD 3714 (220/436)...\n",
      "Processing CD 3909 (230/436)...\n",
      "Processing CD 4004 (240/436)...\n",
      "Processing CD 409 (250/436)...\n",
      "Processing CD 4204 (260/436)...\n",
      "Processing CD 4214 (270/436)...\n",
      "Processing CD 4505 (280/436)...\n",
      "Processing CD 4707 (290/436)...\n",
      "Processing CD 4808 (300/436)...\n",
      "Processing CD 4818 (310/436)...\n",
      "Processing CD 4828 (320/436)...\n",
      "Processing CD 4838 (330/436)...\n",
      "Processing CD 5101 (340/436)...\n",
      "Processing CD 5111 (350/436)...\n",
      "Processing CD 5310 (360/436)...\n",
      "Processing CD 5508 (370/436)...\n",
      "Processing CD 609 (380/436)...\n",
      "Processing CD 619 (390/436)...\n",
      "Processing CD 629 (400/436)...\n",
      "Processing CD 639 (410/436)...\n",
      "Processing CD 649 (420/436)...\n",
      "Processing CD 807 (430/436)...\n",
      "Processing CD 905 (436/436)...\n",
      "\n",
      "Combining 436 CD DataFrames...\n",
      "Total households across all CDs: 50,002\n",
      "Combined DataFrame shape: (152001, 185)\n",
      "\n",
      "Weights in combined_df BEFORE reindexing:\n",
      "  HH weight sum: 1.06M\n",
      "  Person weight sum: 1.06M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Reindexing all entity IDs using 25k ranges per CD...\n",
      "  Created 50,002 unique households across 436 CDs\n",
      "  Reindexing persons using 25k ranges...\n",
      "  Reindexing tax units...\n",
      "  Reindexing SPM units...\n",
      "  Reindexing marital units...\n",
      "  Final persons: 152,001\n",
      "  Final households: 50,002\n",
      "  Final tax units: 70,803\n",
      "  Final SPM units: 52,275\n",
      "  Final marital units: 116,736\n",
      "\n",
      "Weights in combined_df AFTER reindexing:\n",
      "  HH weight sum: 1.06M\n",
      "  Person weight sum: 1.06M\n",
      "  Ratio: 1.00\n",
      "\n",
      "Overflow check:\n",
      "  Max person ID after reindexing: 15,875,309\n",
      "  Max person ID × 100: 1,587,530,900\n",
      "  int32 max: 2,147,483,647\n",
      "  ✓ No overflow risk!\n",
      "\n",
      "Creating Dataset from combined DataFrame...\n",
      "Building simulation from Dataset...\n",
      "\n",
      "Saving to ./temp/national.h5...\n",
      "Found 168 input variables (excluding calculated variables)\n",
      "Also freezing 1 state-dependent calculated variables\n",
      "Variables saved: 192\n",
      "Variables skipped: 3212\n",
      "Sparse CD-stacked dataset saved successfully!\n",
      "Household mapping saved to ./temp/mappings/national_household_mapping.csv\n",
      "\n",
      "Verifying saved file...\n",
      "  Final households: 50,002\n",
      "  Final persons: 152,001\n",
      "  Total population (from household weights): 350,023\n",
      "  Total population (from person weights): 1,064,034\n",
      "  Average persons per household: 3.04\n"
     ]
    }
   ],
   "source": [
    "output_path = f\"{output_dir}/national.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    cds_to_calibrate,\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    "    freeze_calculated_vars=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50002, 5)\n",
      "50002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>household_id</th>\n",
       "      <th>household_weight</th>\n",
       "      <th>congressional_district_geoid</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>snap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   household_id  household_weight  congressional_district_geoid  state_fips  \\\n",
       "0             0               7.0                          1001          10   \n",
       "1             1               7.0                          1001          10   \n",
       "2             2               7.0                          1001          10   \n",
       "3             3               7.0                          1001          10   \n",
       "4             4               7.0                          1001          10   \n",
       "\n",
       "   snap  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_test = Microsimulation(dataset=output_path)\n",
    "hh_snap_df = pd.DataFrame(sim_test.calculate_dataframe([\n",
    "    \"household_id\", \"household_weight\", \"congressional_district_geoid\", \"state_fips\", \"snap\"])\n",
    ")\n",
    "\n",
    "assert np.sum(w > 0) == hh_snap_df.shape[0], f\"Expected {np.sum(w > 0)} rows, got {hh_snap_df.shape[0]}\"\n",
    "print(hh_snap_df.shape)\n",
    "print(np.sum(w > 0))\n",
    "hh_snap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1598, 5)\n",
      "(1, 5889488)\n",
      "       household_id  household_weight  congressional_district_geoid  \\\n",
      "23789       5150000               7.0                          3701   \n",
      "23790       5150001               7.0                          3701   \n",
      "23791       5150002               7.0                          3701   \n",
      "23792       5150003               7.0                          3701   \n",
      "23793       5150004               7.0                          3701   \n",
      "\n",
      "       state_fips    snap  \n",
      "23789          37  1243.5  \n",
      "23790          37     0.0  \n",
      "23791          37     0.0  \n",
      "23792          37     0.0  \n",
      "23793          37     0.0  \n",
      "       household_id  household_weight  congressional_district_geoid  \\\n",
      "25382       5475112               7.0                          3714   \n",
      "25383       5475113               7.0                          3714   \n",
      "25384       5475114               7.0                          3714   \n",
      "25385       5475115               7.0                          3714   \n",
      "25386       5475116               7.0                          3714   \n",
      "\n",
      "       state_fips  snap  \n",
      "25382          37   0.0  \n",
      "25383          37   0.0  \n",
      "25384          37   0.0  \n",
      "25385          37   0.0  \n",
      "25386          37   0.0  \n"
     ]
    }
   ],
   "source": [
    "print(geo_1_df.shape)\n",
    "print(X_sparse[row_loc, :].shape)\n",
    "print(geo_1_df.head())\n",
    "print(geo_1_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_1_df['col_position'] = np.nan\n",
    "geo_1_df['X_sparse_value'] = np.nan\n",
    "geo_1_df['w_value'] = np.nan\n",
    "\n",
    "for i in range(geo_1_df.shape[0]):\n",
    "    df_hh_id_new = geo_1_df.iloc[i]['household_id']\n",
    "    # get the old household id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target row info: {'row_index': 33194, 'variable': 'snap', 'variable_desc': 'snap_cost_state', 'geographic_id': '37', 'geographic_level': 'unknown', 'target_value': 4041086120.0, 'stratum_id': 9799, 'stratum_group_id': 'state_snap_cost'}\n",
      "{'row_index': 33194, 'variable': 'snap', 'variable_desc': 'snap_cost_state', 'geographic_id': '37', 'geographic_level': 'unknown', 'target_value': 4041086120.0, 'stratum_id': 9799, 'stratum_group_id': 'state_snap_cost'}\n",
      "37\n",
      "(1598, 5)\n",
      "Matrix multiplication (X @ w)[33194] = 2,895,502.61\n",
      "Simulation sum(snap * weight) for state 1 = 2,920,930.08\n",
      "Matrix nonzero: 14574, Sim nonzero: 129\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(12.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "Weight from matrix columns: 12.0\n",
      "Weight from sim: 11191.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Mismatch: 2920930.082221985 vs 2895502.609931946",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight from matrix columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msum(w_in_state)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight from sim: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeo_1_df\u001b[38;5;241m.\u001b[39mhousehold_weight\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(y_hat_sim, snap_hat_geo1, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_hat_sim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msnap_hat_geo1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnd-to-end validation PASSED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Mismatch: 2920930.082221985 vs 2895502.609931946"
     ]
    }
   ],
   "source": [
    "print(f\"Target row info: {row_info}\")\n",
    "\n",
    "y_hat = X_sparse @ w\n",
    "\n",
    "# Ok, but hang on, you have two districts from two different states, but you \n",
    "# didn't use them here. The geo should be NC\n",
    "print(row_info)\n",
    "print(target_geo_id)\n",
    "\n",
    "snap_hat_geo1 = y_hat[row_loc]\n",
    "\n",
    "geo_1_df = hh_snap_df.loc[hh_snap_df.state_fips == target_geo_id]\n",
    "y_hat_sim = np.sum(geo_1_df.snap.values * geo_1_df.household_weight.values)\n",
    "print(geo_1_df.shape)\n",
    "\n",
    "print(f\"Matrix multiplication (X @ w)[{row_loc}] = {snap_hat_geo1:,.2f}\")\n",
    "print(f\"Simulation sum(snap * weight) for state 1 = {y_hat_sim:,.2f}\")\n",
    "\n",
    "# Check if household counts match\n",
    "n_matrix = np.sum(X_sparse[row_loc, :].toarray() > 0)\n",
    "n_sim = (geo_1_df.snap > 0).sum()\n",
    "print(f\"Matrix nonzero: {n_matrix}, Sim nonzero: {n_sim}\")\n",
    "\n",
    "assert np.isclose(y_hat_sim, snap_hat_geo1, atol=10), f\"Mismatch: {y_hat_sim} vs {snap_hat_geo1}\"\n",
    "print(\"\\nEnd-to-end validation PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target row info: {'row_index': 33194, 'variable': 'snap', 'variable_desc': 'snap_cost_state', 'geographic_id': '37', 'geographic_level': 'unknown', 'target_value': 4041086120.0, 'stratum_id': 9799, 'stratum_group_id': 'state_snap_cost'}\n",
      "{'row_index': 33194, 'variable': 'snap', 'variable_desc': 'snap_cost_state', 'geographic_id': '37', 'geographic_level': 'unknown', 'target_value': 4041086120.0, 'stratum_id': 9799, 'stratum_group_id': 'state_snap_cost'}\n",
      "37\n",
      "(1598, 5)\n",
      "Matrix multiplication (X @ w)[33194] = 2,895,502.61\n",
      "Simulation sum(snap * weight) for state 1 = 2,920,930.08\n",
      "Matrix nonzero: 14574, Sim nonzero: 129\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(12.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "Weight from matrix columns: 12.0\n",
      "Weight from sim: 11191.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Mismatch: 2920930.082221985 vs 2895502.609931946",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight from matrix columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msum(w_in_state)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight from sim: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeo_1_df\u001b[38;5;241m.\u001b[39mhousehold_weight\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(y_hat_sim, snap_hat_geo1, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_hat_sim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msnap_hat_geo1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnd-to-end validation PASSED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Mismatch: 2920930.082221985 vs 2895502.609931946"
     ]
    }
   ],
   "source": [
    "print(f\"Target row info: {row_info}\")\n",
    "\n",
    "y_hat = X_sparse @ w\n",
    "\n",
    "# Ok, but hang on, you have two districts from two different states, but you \n",
    "# didn't use them here. The geo should be NC\n",
    "print(row_info)\n",
    "print(target_geo_id)\n",
    "\n",
    "snap_hat_geo1 = y_hat[row_loc]\n",
    "\n",
    "geo_1_df = hh_snap_df.loc[hh_snap_df.state_fips == target_geo_id]\n",
    "y_hat_sim = np.sum(geo_1_df.snap.values * geo_1_df.household_weight.values)\n",
    "print(geo_1_df.shape)\n",
    "\n",
    "print(f\"Matrix multiplication (X @ w)[{row_loc}] = {snap_hat_geo1:,.2f}\")\n",
    "print(f\"Simulation sum(snap * weight) for state 1 = {y_hat_sim:,.2f}\")\n",
    "\n",
    "# Check if household counts match\n",
    "n_matrix = np.sum(X_sparse[row_loc, :].toarray() > 0)\n",
    "n_sim = (geo_1_df.snap > 0).sum()\n",
    "print(f\"Matrix nonzero: {n_matrix}, Sim nonzero: {n_sim}\")\n",
    "\n",
    "# Check total weights\n",
    "w_in_state = [w[hh_col_lku[cd]] for cd in hh_col_lku if int(cd)//100 == target_geo_id]\n",
    "print(w_in_state)\n",
    "print(f\"Weight from matrix columns: {np.sum(w_in_state)}\")\n",
    "print(f\"Weight from sim: {geo_1_df.household_weight.sum()}\")\n",
    "\n",
    "assert np.isclose(y_hat_sim, snap_hat_geo1, atol=10), f\"Mismatch: {y_hat_sim} vs {snap_hat_geo1}\"\n",
    "print(\"\\nEnd-to-end validation PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target row info: {'row_index': 33194, 'variable': 'snap', 'variable_desc': 'snap_cost_state', 'geographic_id': '37', 'geographic_level': 'unknown', 'target_value': 4041086120.0, 'stratum_id': 9799, 'stratum_group_id': 'state_snap_cost'}\n",
      "{'row_index': 33194, 'variable': 'snap', 'variable_desc': 'snap_cost_state', 'geographic_id': '37', 'geographic_level': 'unknown', 'target_value': 4041086120.0, 'stratum_id': 9799, 'stratum_group_id': 'state_snap_cost'}\n",
      "37\n",
      "(1598, 5)\n",
      "Matrix multiplication (X @ w)[33194] = 2,895,502.61\n",
      "Simulation sum(snap * weight) for state 1 = 2,920,930.08\n",
      "Matrix nonzero: 14574, Sim nonzero: 129\n",
      "[np.float64(0.0), np.float64(0.0), np.float64(12.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)]\n",
      "Weight from matrix columns: 12.0\n",
      "Weight from sim: 11191.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Mismatch: 2920930.082221985 vs 2895502.609931946",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight from matrix columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msum(w_in_state)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight from sim: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeo_1_df\u001b[38;5;241m.\u001b[39mhousehold_weight\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(y_hat_sim, snap_hat_geo1, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_hat_sim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msnap_hat_geo1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnd-to-end validation PASSED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Mismatch: 2920930.082221985 vs 2895502.609931946"
     ]
    }
   ],
   "source": [
    "print(f\"Target row info: {row_info}\")\n",
    "\n",
    "y_hat = X_sparse @ w\n",
    "\n",
    "# Ok, but hang on, you have two districts from two different states, but you \n",
    "# didn't use them here. The geo should be NC\n",
    "print(row_info)\n",
    "print(target_geo_id)\n",
    "\n",
    "snap_hat_geo1 = y_hat[row_loc]\n",
    "\n",
    "geo_1_df = hh_snap_df.loc[hh_snap_df.state_fips == target_geo_id]\n",
    "y_hat_sim = np.sum(geo_1_df.snap.values * geo_1_df.household_weight.values)\n",
    "print(geo_1_df.shape)\n",
    "\n",
    "print(f\"Matrix multiplication (X @ w)[{row_loc}] = {snap_hat_geo1:,.2f}\")\n",
    "print(f\"Simulation sum(snap * weight) for state 1 = {y_hat_sim:,.2f}\")\n",
    "\n",
    "# Check if household counts match\n",
    "n_matrix = np.sum(X_sparse[row_loc, :].toarray() > 0)\n",
    "n_sim = (geo_1_df.snap > 0).sum()\n",
    "print(f\"Matrix nonzero: {n_matrix}, Sim nonzero: {n_sim}\")\n",
    "\n",
    "# Check total weights\n",
    "w_in_state = [w[hh_col_lku[cd]] for cd in hh_col_lku if int(cd)//100 == target_geo_id]\n",
    "print(w_in_state)\n",
    "print(f\"Weight from matrix columns: {np.sum(w_in_state)}\")\n",
    "print(f\"Weight from sim: {geo_1_df.household_weight.sum()}\")\n",
    "\n",
    "assert np.isclose(y_hat_sim, snap_hat_geo1, atol=10), f\"Mismatch: {y_hat_sim} vs {snap_hat_geo1}\"\n",
    "print(\"\\nEnd-to-end validation PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./temp\"\n",
    "w = np.load('w_cd_20251126_131911.npy')\n",
    "print(len(w))\n",
    "print(len(cds_to_calibrate))\n",
    "\n",
    "print(w)\n",
    "print(dataset_uri)\n",
    "output_path = f\"{output_dir}/RI.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    cds_to_calibrate,\n",
    "    ['4401', '4402'],\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    "    freeze_calculated_vars=False,\n",
    ")\n",
    "\n",
    "for i in range(51):\n",
    "    row_loc = group_71.iloc[i]['row_index']\n",
    "    row_info = tracer.get_row_info(row_loc)\n",
    "    var = row_info['variable']\n",
    "    var_desc = row_info['variable_desc']\n",
    "    target_geo_id = int(row_info['geographic_id'])\n",
    "    if target_geo_id == 44:\n",
    "        break\n",
    "\n",
    "print(\"Row info for first SNAP state target:\")\n",
    "row_info\n",
    "print(f\"Target row info: {row_info}\")\n",
    "\n",
    "y_hat = X_sparse @ w\n",
    "snap_hat_geo44 = y_hat[row_loc]\n",
    "\n",
    "sim_test = Microsimulation(dataset=output_path)\n",
    "hh_snap_df = pd.DataFrame(sim_test.calculate_dataframe([\n",
    "    \"household_id\", \"household_weight\", \"congressional_district_geoid\", \"state_fips\", \"snap\"])\n",
    ")\n",
    "\n",
    "geo_44_df = hh_snap_df.loc[hh_snap_df.state_fips == 44]\n",
    "y_hat_sim = np.sum(geo_44_df.snap.values * geo_44_df.household_weight.values)\n",
    "\n",
    "print(\"\\nThe calibration dashboard shows and estimate of 393.86M\")\n",
    "print(f\"Matrix multiplication (X @ w)[{row_loc}] = {snap_hat_geo44:,.2f}\")\n",
    "print(f\"Simulation sum(snap * weight) for state 44 = {y_hat_sim:,.2f}\")\n",
    "\n",
    "assert np.isclose(y_hat_sim, snap_hat_geo44, atol=10), f\"Mismatch: {y_hat_sim} vs {snap_hat_geo44}\"\n",
    "print(\"\\nFull Weight from Model fitting - End-to-end validation PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists('./temp'):\n",
    "    shutil.rmtree('./temp')\n",
    "    print(\"Cleaned up ./temp directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f\"{output_dir}/3714.h5\"\n",
    "output_file = create_sparse_cd_stacked_dataset(\n",
    "    w,\n",
    "    ['3714'],\n",
    "    dataset_path=str(dataset_uri),\n",
    "    output_path=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
