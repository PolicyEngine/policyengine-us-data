{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6dc9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from policyengine_us_data.utils.minimise import minimise_dataset, random_sampling_minimization, candidate_loss_contribution\n",
    "from policyengine_us_data.storage import STORAGE_FOLDER\n",
    "from policyengine_us import Microsimulation\n",
    "from policyengine_us_data.datasets.cps.enhanced_cps import reweight, ExtendedCPS_2024\n",
    "from policyengine_us_data.utils import build_loss_matrix\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "bad_targets = [\n",
    "    \"nation/irs/adjusted gross income/total/AGI in 10k-15k/taxable/Head of Household\",\n",
    "    \"nation/irs/adjusted gross income/total/AGI in 15k-20k/taxable/Head of Household\",\n",
    "    \"nation/irs/adjusted gross income/total/AGI in 10k-15k/taxable/Married Filing Jointly/Surviving Spouse\",\n",
    "    \"nation/irs/adjusted gross income/total/AGI in 15k-20k/taxable/Married Filing Jointly/Surviving Spouse\",\n",
    "    \"nation/irs/count/count/AGI in 10k-15k/taxable/Head of Household\",\n",
    "    \"nation/irs/count/count/AGI in 15k-20k/taxable/Head of Household\",\n",
    "    \"nation/irs/count/count/AGI in 10k-15k/taxable/Married Filing Jointly/Surviving Spouse\",\n",
    "    \"nation/irs/count/count/AGI in 15k-20k/taxable/Married Filing Jointly/Surviving Spouse\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683fd57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of household entity in the dataset measured through household_weight:\n",
    "\n",
    "# Original ECPS 2024 dataset size: 41310\n",
    "# Through \"random_sampling_minimization\" with 0.5 of the dataset being pruned: 20655\n",
    "# Through \"random_sampling_minimization\" with 0.2 of the dataset being pruned: 33408\n",
    "# After minimization through \"candidate_loss_contribution\" and a 1.0 max error change: 20655 \n",
    "# After minimization through \"candidate_loss_contribution\" and a 0.001 max error change: 24786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db975ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL TESTS\n",
    "\n",
    "## For L1 and L0 penalty approaches which are integrated into the enhanced CPS dataset creation\n",
    "\n",
    "input_dataset = ExtendedCPS_2024\n",
    "\n",
    "approaches = [\"l0_sigmoid\", \"l0_log\", \"l0_exp\", \"l1\"]\n",
    "\n",
    "for approach in approaches:\n",
    "    sim = Microsimulation(dataset=input_dataset)\n",
    "    data = sim.dataset.load_dataset()\n",
    "    data[\"household_weight\"] = {}\n",
    "    original_weights = sim.calculate(\"household_weight\")\n",
    "    original_weights = original_weights.values + np.random.normal(\n",
    "        1, 0.1, len(original_weights)\n",
    "    )\n",
    "    for year in range(2024, 2025):\n",
    "        loss_matrix, targets_array = build_loss_matrix(\n",
    "            input_dataset, year\n",
    "        )\n",
    "\n",
    "        bad_mask = loss_matrix.columns.isin(bad_targets)\n",
    "        keep_mask_bool = ~bad_mask\n",
    "        keep_idx = np.where(keep_mask_bool)[0]\n",
    "        loss_matrix_clean = loss_matrix.iloc[:, keep_idx]\n",
    "        targets_array_clean = targets_array[keep_idx]\n",
    "        assert loss_matrix_clean.shape[1] == targets_array_clean.size\n",
    "\n",
    "        optimised_weights = reweight(\n",
    "            original_weights,\n",
    "            loss_matrix_clean,\n",
    "            targets_array_clean,\n",
    "            log_path=\"calibration_log.csv\",\n",
    "            penalty_approach=approach,\n",
    "            epochs=250,  # Reduced epochs for faster processing\n",
    "        )\n",
    "        data[\"household_weight\"][year] = optimised_weights\n",
    "\n",
    "    output_path = STORAGE_FOLDER / approach / \"enhanced_cps_2024_minimised.h5\"\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save to HDF5 file\n",
    "    with h5py.File(output_path, \"w\") as f:\n",
    "        for variable, values in data.items():\n",
    "            for year, value in values.items():\n",
    "                f.create_dataset(f\"{variable}/{year}\", data=value)\n",
    "\n",
    "\n",
    "## For approaches external to the reweighting approach implemented in enhanced CPS dataset creation\n",
    "\n",
    "files = [\n",
    "        STORAGE_FOLDER / \"enhanced_cps_2024.h5\",\n",
    "    ]\n",
    "\n",
    "approaches = {\n",
    "        \"random_sampling_minimization\": random_sampling_minimization,\n",
    "        \"candidate_loss_contribution\": candidate_loss_contribution,\n",
    "}\n",
    "\n",
    "optional_params = {\n",
    "        \"random_sampling_minimization\": {\n",
    "            \"target_fractions\": [0.5, 0.6, 0.7, 0.8, 0.9],  # fractions of the dataset to keep\n",
    "        },\n",
    "        \"candidate_loss_contribution\": {\n",
    "            \"loss_rel_change_max\": [0.00001, 0.000001, 0.0000001] # maximum relative change in\n",
    "        }\n",
    "}\n",
    "\n",
    "for approach, function in approaches.items():\n",
    "    minimization_function = function\n",
    "    # other minimization function approach is \"random_sampling_minimization\", for which you can specify the tolerance for loss relative change.\n",
    "\n",
    "    for params, values in optional_params[approach].items():\n",
    "        for value in values:\n",
    "            if params == \"target_fractions\":\n",
    "                for file in files:\n",
    "                    output_path = STORAGE_FOLDER / approach / f\"{value}_enhanced_cps_2024_minimised.h5\"\n",
    "                    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    minimise_dataset(\n",
    "                        file,\n",
    "                        output_path,\n",
    "                        minimization_function=minimization_function, \n",
    "                        target_fractions=[value]\n",
    "                    )\n",
    "            elif params == \"loss_rel_change_max\":\n",
    "                for file in files:\n",
    "                    output_path = STORAGE_FOLDER / approach / f\"{value}_enhanced_cps_2024_minimised.h5\"\n",
    "                    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    minimise_dataset(\n",
    "                        file,\n",
    "                        output_path,\n",
    "                        minimization_function=minimization_function, \n",
    "                        loss_rel_change_max=value\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35892c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SMALL CHECKS BELOW -- IGNORE ---\n",
    "\n",
    "## For approaches external to the reweighting approach implemented in enhanced CPS dataset creation\n",
    "\n",
    "files = [\n",
    "        STORAGE_FOLDER / \"enhanced_cps_2024.h5\",\n",
    "    ]\n",
    "\n",
    "minimization_function = random_sampling_minimization\n",
    "# other minimization function approach is \"random_sampling_minimization\", for which you can specify the tolerance for loss relative change.\n",
    "\n",
    "for file in files:\n",
    "    output_path = STORAGE_FOLDER / \"random_sampling_minimization\" / f\"{1.0}_enhanced_cps_2024_minimised.h5\"\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    minimise_dataset(\n",
    "        file,\n",
    "        output_path,\n",
    "        minimization_function=minimization_function, \n",
    "        target_fractions=[1.0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf8e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:24<00:00,  2.98it/s, loss=3.37e-5, loss_rel_change=-0.92] \n"
     ]
    }
   ],
   "source": [
    "input_dataset = ExtendedCPS_2024\n",
    "\n",
    "sim = Microsimulation(dataset=input_dataset)\n",
    "data = sim.dataset.load_dataset()\n",
    "data[\"household_weight\"] = {}\n",
    "original_weights = sim.calculate(\"household_weight\")\n",
    "original_weights = original_weights.values + np.random.normal(\n",
    "    1, 0.1, len(original_weights)\n",
    ")\n",
    "for year in range(2024, 2025):\n",
    "    loss_matrix, targets_array = build_loss_matrix(\n",
    "        input_dataset, year\n",
    "    )\n",
    "\n",
    "    bad_mask = loss_matrix.columns.isin(bad_targets)\n",
    "    keep_mask_bool = ~bad_mask\n",
    "    keep_idx = np.where(keep_mask_bool)[0]\n",
    "    loss_matrix_clean = loss_matrix.iloc[:, keep_idx]\n",
    "    targets_array_clean = targets_array[keep_idx]\n",
    "    assert loss_matrix_clean.shape[1] == targets_array_clean.size\n",
    "    assert loss_matrix_clean.shape[1] != loss_matrix.shape[1]\n",
    "\n",
    "    optimised_weights = reweight(\n",
    "        original_weights,\n",
    "        loss_matrix_clean,\n",
    "        targets_array_clean,\n",
    "        log_path=\"baseline_calibration_log.csv\",\n",
    "        epochs=250,  # Reduced epochs for faster processing\n",
    "    )\n",
    "    data[\"household_weight\"][year] = optimised_weights\n",
    "\n",
    "output_path = STORAGE_FOLDER / \"baseline\" / \"enhanced_cps_2024_baseline.h5\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save to HDF5 file\n",
    "with h5py.File(output_path, \"w\") as f:\n",
    "    for variable, values in data.items():\n",
    "        for year, value in values.items():\n",
    "            f.create_dataset(f\"{variable}/{year}\", data=value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
