{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6dc9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from policyengine_us_data.utils.minimise import minimise_dataset, random_sampling_minimization, candidate_loss_contribution\n",
    "from policyengine_us_data.storage import STORAGE_FOLDER\n",
    "from policyengine_us import Microsimulation\n",
    "from policyengine_us_data.datasets.cps.enhanced_cps import reweight, ExtendedCPS_2024\n",
    "from policyengine_us_data.utils import build_loss_matrix\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "bad_targets = [\n",
    "    \"nation/irs/adjusted gross income/total/AGI in 10k-15k/taxable/Head of Household\",\n",
    "    \"nation/irs/adjusted gross income/total/AGI in 15k-20k/taxable/Head of Household\",\n",
    "    \"nation/irs/adjusted gross income/total/AGI in 10k-15k/taxable/Married Filing Jointly/Surviving Spouse\",\n",
    "    \"nation/irs/adjusted gross income/total/AGI in 15k-20k/taxable/Married Filing Jointly/Surviving Spouse\",\n",
    "    \"nation/irs/count/count/AGI in 10k-15k/taxable/Head of Household\",\n",
    "    \"nation/irs/count/count/AGI in 15k-20k/taxable/Head of Household\",\n",
    "    \"nation/irs/count/count/AGI in 10k-15k/taxable/Married Filing Jointly/Surviving Spouse\",\n",
    "    \"nation/irs/count/count/AGI in 15k-20k/taxable/Married Filing Jointly/Surviving Spouse\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683fd57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of household entity in the dataset measured through household_weight:\n",
    "\n",
    "# Original ECPS 2024 dataset size: 41310\n",
    "# Through \"random_sampling_minimization\" with 0.5 of the dataset being pruned: 20655\n",
    "# Through \"random_sampling_minimization\" with 0.2 of the dataset being pruned: 33408\n",
    "# After minimization through \"candidate_loss_contribution\" and a 1.0 max error change: 20655 \n",
    "# After minimization through \"candidate_loss_contribution\" and a 0.001 max error change: 24786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db975ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.00it/s, loss=9.1e-5, loss_rel_change=-0.809] \n",
      "100%|██████████| 10/10 [00:03<00:00,  2.96it/s, loss=0.000181, loss_rel_change=-0.679]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.98it/s, loss=0.00108, loss_rel_change=-0.273]\n"
     ]
    }
   ],
   "source": [
    "## ALL TESTS\n",
    "\n",
    "## For L1 and L0 penalty approaches which are integrated into the enhanced CPS dataset creation\n",
    "\n",
    "input_dataset = ExtendedCPS_2024\n",
    "\n",
    "approaches = [\"l0_sigmoid\", \"l0_log\", \"l0_exp\", \"l1\"]\n",
    "penalty_weights = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "def get_output_path(approach, file_name):\n",
    "    output_path = STORAGE_FOLDER / approach / file_name\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    return output_path\n",
    "\n",
    "results = []\n",
    "\n",
    "for approach in approaches:\n",
    "            for penalty_weight in penalty_weights:\n",
    "                # Storing files in correct locations\n",
    "                cal_log_name = f\"calibration_log_{approach}_{penalty_weight}.csv\"\n",
    "                h5_name = f\"enhanced_cps_2024_{approach}_{penalty_weight}_minimised.h5\"\n",
    "                cal_log_path = get_output_path(approach, cal_log_name)\n",
    "                h5_path = get_output_path(approach, h5_name)\n",
    "\n",
    "                sim = Microsimulation(dataset=input_dataset)\n",
    "                data = sim.dataset.load_dataset()\n",
    "                data[\"household_weight\"] = {}\n",
    "                original_weights = sim.calculate(\"household_weight\")\n",
    "                original_weights = original_weights.values + np.random.normal(\n",
    "                    1, 0.1, len(original_weights)\n",
    "                )\n",
    "                for year in range(2024, 2025):\n",
    "                    loss_matrix, targets_array = build_loss_matrix(\n",
    "                        input_dataset, year\n",
    "                    )\n",
    "\n",
    "                    bad_mask = loss_matrix.columns.isin(bad_targets)\n",
    "                    keep_mask_bool = ~bad_mask\n",
    "                    keep_idx = np.where(keep_mask_bool)[0]\n",
    "                    loss_matrix_clean = loss_matrix.iloc[:, keep_idx]\n",
    "                    targets_array_clean = targets_array[keep_idx]\n",
    "                    assert loss_matrix_clean.shape[1] == targets_array_clean.size\n",
    "\n",
    "                    optimised_weights = reweight(\n",
    "                        original_weights,\n",
    "                        loss_matrix_clean,\n",
    "                        targets_array_clean,\n",
    "                        log_path=cal_log_path, \n",
    "                        penalty_approach=approach,\n",
    "                        penalty_weight=penalty_weight, \n",
    "                        epochs=10,  # Reduced epochs for faster processing\n",
    "                    )\n",
    "                    data[\"household_weight\"][year] = optimised_weights\n",
    "\n",
    "                # Save to HDF5 file\n",
    "                with h5py.File(h5_path, \"w\") as f:\n",
    "                    for variable, values in data.items():\n",
    "                        for year, value in values.items():\n",
    "                            f.create_dataset(f\"{variable}/{year}\", data=value)\n",
    "\n",
    "\n",
    "## For approaches external to the reweighting approach implemented in enhanced CPS dataset creation\n",
    "\n",
    "files = [\n",
    "        STORAGE_FOLDER / \"enhanced_cps_2024.h5\",\n",
    "    ]\n",
    "\n",
    "approaches = {\n",
    "        \"random_sampling_minimization\": random_sampling_minimization,\n",
    "        \"candidate_loss_contribution\": candidate_loss_contribution,\n",
    "}\n",
    "\n",
    "optional_params = {\n",
    "        \"random_sampling_minimization\": {\n",
    "            \"target_fractions\": [0.5, 0.6, 0.7, 0.8, 0.9],  # fractions of the dataset to keep\n",
    "        },\n",
    "        \"candidate_loss_contribution\": {\n",
    "            \"loss_rel_change_max\": [0.001, 0.0001, 0.00001, 0.000001, 0.0000001] # maximum relative change in loss\n",
    "        }\n",
    "}\n",
    "\n",
    "for approach, function in approaches.items():\n",
    "    minimization_function = function\n",
    "    # other minimization function approach is \"random_sampling_minimization\", for which you can specify the tolerance for loss relative change.\n",
    "\n",
    "    for params, values in optional_params[approach].items():\n",
    "        for value in values:\n",
    "            if params == \"target_fractions\":\n",
    "                for file in files:\n",
    "                    output_path = STORAGE_FOLDER / approach / f\"{value}_enhanced_cps_2024_minimised.h5\"\n",
    "                    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    minimise_dataset(\n",
    "                        file,\n",
    "                        output_path,\n",
    "                        minimization_function=minimization_function, \n",
    "                        target_fractions=[value]\n",
    "                    )\n",
    "            elif params == \"loss_rel_change_max\":\n",
    "                for file in files:\n",
    "                    output_path = STORAGE_FOLDER / approach / f\"{value}_enhanced_cps_2024_minimised.h5\"\n",
    "                    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    minimise_dataset(\n",
    "                        file,\n",
    "                        output_path,\n",
    "                        minimization_function=minimization_function, \n",
    "                        loss_rel_change_max=value\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35892c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targeting Medicaid enrollment for AK with target 231577k\n",
      "Targeting Medicaid enrollment for AL with target 766009k\n",
      "Targeting Medicaid enrollment for AR with target 733561k\n",
      "Targeting Medicaid enrollment for AZ with target 1778734k\n",
      "Targeting Medicaid enrollment for CA with target 12172695k\n",
      "Targeting Medicaid enrollment for CO with target 1058326k\n",
      "Targeting Medicaid enrollment for CT with target 904321k\n",
      "Targeting Medicaid enrollment for DC with target 240020k\n",
      "Targeting Medicaid enrollment for DE with target 236840k\n",
      "Targeting Medicaid enrollment for FL with target 3568648k\n",
      "Targeting Medicaid enrollment for GA with target 1699279k\n",
      "Targeting Medicaid enrollment for HI with target 376318k\n",
      "Targeting Medicaid enrollment for IA with target 586748k\n",
      "Targeting Medicaid enrollment for ID with target 296968k\n",
      "Targeting Medicaid enrollment for IL with target 2918179k\n",
      "Targeting Medicaid enrollment for IN with target 1623361k\n",
      "Targeting Medicaid enrollment for KS with target 335902k\n",
      "Targeting Medicaid enrollment for KY with target 1244822k\n",
      "Targeting Medicaid enrollment for LA with target 1377806k\n",
      "Targeting Medicaid enrollment for MA with target 1453344k\n",
      "Targeting Medicaid enrollment for MD with target 1280697k\n",
      "Targeting Medicaid enrollment for ME with target 322306k\n",
      "Targeting Medicaid enrollment for MI with target 2194067k\n",
      "Targeting Medicaid enrollment for MN with target 1146667k\n",
      "Targeting Medicaid enrollment for MO with target 1118780k\n",
      "Targeting Medicaid enrollment for MS with target 514730k\n",
      "Targeting Medicaid enrollment for MT with target 193278k\n",
      "Targeting Medicaid enrollment for NC with target 2469712k\n",
      "Targeting Medicaid enrollment for ND with target 100543k\n",
      "Targeting Medicaid enrollment for NE with target 302971k\n",
      "Targeting Medicaid enrollment for NH with target 166813k\n",
      "Targeting Medicaid enrollment for NJ with target 1506239k\n",
      "Targeting Medicaid enrollment for NM with target 686825k\n",
      "Targeting Medicaid enrollment for NV with target 713936k\n",
      "Targeting Medicaid enrollment for NY with target 5946806k\n",
      "Targeting Medicaid enrollment for OH with target 2596879k\n",
      "Targeting Medicaid enrollment for OK with target 894911k\n",
      "Targeting Medicaid enrollment for OR with target 1123313k\n",
      "Targeting Medicaid enrollment for PA with target 2783389k\n",
      "Targeting Medicaid enrollment for RI with target 273400k\n",
      "Targeting Medicaid enrollment for SC with target 932515k\n",
      "Targeting Medicaid enrollment for SD with target 126952k\n",
      "Targeting Medicaid enrollment for TN with target 1268904k\n",
      "Targeting Medicaid enrollment for TX with target 3821806k\n",
      "Targeting Medicaid enrollment for UT with target 300742k\n",
      "Targeting Medicaid enrollment for VA with target 1596777k\n",
      "Targeting Medicaid enrollment for VT with target 151833k\n",
      "Targeting Medicaid enrollment for WA with target 1776116k\n",
      "Targeting Medicaid enrollment for WI with target 1108320k\n",
      "Targeting Medicaid enrollment for WV with target 467632k\n",
      "Targeting Medicaid enrollment for WY with target 57320k\n",
      "Targeting Medicaid enrollment for AK with target 231577k\n",
      "Targeting Medicaid enrollment for AL with target 766009k\n",
      "Targeting Medicaid enrollment for AR with target 733561k\n",
      "Targeting Medicaid enrollment for AZ with target 1778734k\n",
      "Targeting Medicaid enrollment for CA with target 12172695k\n",
      "Targeting Medicaid enrollment for CO with target 1058326k\n",
      "Targeting Medicaid enrollment for CT with target 904321k\n",
      "Targeting Medicaid enrollment for DC with target 240020k\n",
      "Targeting Medicaid enrollment for DE with target 236840k\n",
      "Targeting Medicaid enrollment for FL with target 3568648k\n",
      "Targeting Medicaid enrollment for GA with target 1699279k\n",
      "Targeting Medicaid enrollment for HI with target 376318k\n",
      "Targeting Medicaid enrollment for IA with target 586748k\n",
      "Targeting Medicaid enrollment for ID with target 296968k\n",
      "Targeting Medicaid enrollment for IL with target 2918179k\n",
      "Targeting Medicaid enrollment for IN with target 1623361k\n",
      "Targeting Medicaid enrollment for KS with target 335902k\n",
      "Targeting Medicaid enrollment for KY with target 1244822k\n",
      "Targeting Medicaid enrollment for LA with target 1377806k\n",
      "Targeting Medicaid enrollment for MA with target 1453344k\n",
      "Targeting Medicaid enrollment for MD with target 1280697k\n",
      "Targeting Medicaid enrollment for ME with target 322306k\n",
      "Targeting Medicaid enrollment for MI with target 2194067k\n",
      "Targeting Medicaid enrollment for MN with target 1146667k\n",
      "Targeting Medicaid enrollment for MO with target 1118780k\n",
      "Targeting Medicaid enrollment for MS with target 514730k\n",
      "Targeting Medicaid enrollment for MT with target 193278k\n",
      "Targeting Medicaid enrollment for NC with target 2469712k\n",
      "Targeting Medicaid enrollment for ND with target 100543k\n",
      "Targeting Medicaid enrollment for NE with target 302971k\n",
      "Targeting Medicaid enrollment for NH with target 166813k\n",
      "Targeting Medicaid enrollment for NJ with target 1506239k\n",
      "Targeting Medicaid enrollment for NM with target 686825k\n",
      "Targeting Medicaid enrollment for NV with target 713936k\n",
      "Targeting Medicaid enrollment for NY with target 5946806k\n",
      "Targeting Medicaid enrollment for OH with target 2596879k\n",
      "Targeting Medicaid enrollment for OK with target 894911k\n",
      "Targeting Medicaid enrollment for OR with target 1123313k\n",
      "Targeting Medicaid enrollment for PA with target 2783389k\n",
      "Targeting Medicaid enrollment for RI with target 273400k\n",
      "Targeting Medicaid enrollment for SC with target 932515k\n",
      "Targeting Medicaid enrollment for SD with target 126952k\n",
      "Targeting Medicaid enrollment for TN with target 1268904k\n",
      "Targeting Medicaid enrollment for TX with target 3821806k\n",
      "Targeting Medicaid enrollment for UT with target 300742k\n",
      "Targeting Medicaid enrollment for VA with target 1596777k\n",
      "Targeting Medicaid enrollment for VT with target 151833k\n",
      "Targeting Medicaid enrollment for WA with target 1776116k\n",
      "Targeting Medicaid enrollment for WI with target 1108320k\n",
      "Targeting Medicaid enrollment for WV with target 467632k\n",
      "Targeting Medicaid enrollment for WY with target 57320k\n",
      "Weight relative change: 100.00%\n",
      "Saved minimised dataset to /Users/elenacura/Desktop/PolicyEngine/policyengine-us-data/policyengine_us_data/storage/random_sampling_minimization/1.0_enhanced_cps_2024_random_sampling_minimization_minimised.h5\n",
      "Targeting Medicaid enrollment for AK with target 231577k\n",
      "Targeting Medicaid enrollment for AL with target 766009k\n",
      "Targeting Medicaid enrollment for AR with target 733561k\n",
      "Targeting Medicaid enrollment for AZ with target 1778734k\n",
      "Targeting Medicaid enrollment for CA with target 12172695k\n",
      "Targeting Medicaid enrollment for CO with target 1058326k\n",
      "Targeting Medicaid enrollment for CT with target 904321k\n",
      "Targeting Medicaid enrollment for DC with target 240020k\n",
      "Targeting Medicaid enrollment for DE with target 236840k\n",
      "Targeting Medicaid enrollment for FL with target 3568648k\n",
      "Targeting Medicaid enrollment for GA with target 1699279k\n",
      "Targeting Medicaid enrollment for HI with target 376318k\n",
      "Targeting Medicaid enrollment for IA with target 586748k\n",
      "Targeting Medicaid enrollment for ID with target 296968k\n",
      "Targeting Medicaid enrollment for IL with target 2918179k\n",
      "Targeting Medicaid enrollment for IN with target 1623361k\n",
      "Targeting Medicaid enrollment for KS with target 335902k\n",
      "Targeting Medicaid enrollment for KY with target 1244822k\n",
      "Targeting Medicaid enrollment for LA with target 1377806k\n",
      "Targeting Medicaid enrollment for MA with target 1453344k\n",
      "Targeting Medicaid enrollment for MD with target 1280697k\n",
      "Targeting Medicaid enrollment for ME with target 322306k\n",
      "Targeting Medicaid enrollment for MI with target 2194067k\n",
      "Targeting Medicaid enrollment for MN with target 1146667k\n",
      "Targeting Medicaid enrollment for MO with target 1118780k\n",
      "Targeting Medicaid enrollment for MS with target 514730k\n",
      "Targeting Medicaid enrollment for MT with target 193278k\n",
      "Targeting Medicaid enrollment for NC with target 2469712k\n",
      "Targeting Medicaid enrollment for ND with target 100543k\n",
      "Targeting Medicaid enrollment for NE with target 302971k\n",
      "Targeting Medicaid enrollment for NH with target 166813k\n",
      "Targeting Medicaid enrollment for NJ with target 1506239k\n",
      "Targeting Medicaid enrollment for NM with target 686825k\n",
      "Targeting Medicaid enrollment for NV with target 713936k\n",
      "Targeting Medicaid enrollment for NY with target 5946806k\n",
      "Targeting Medicaid enrollment for OH with target 2596879k\n",
      "Targeting Medicaid enrollment for OK with target 894911k\n",
      "Targeting Medicaid enrollment for OR with target 1123313k\n",
      "Targeting Medicaid enrollment for PA with target 2783389k\n",
      "Targeting Medicaid enrollment for RI with target 273400k\n",
      "Targeting Medicaid enrollment for SC with target 932515k\n",
      "Targeting Medicaid enrollment for SD with target 126952k\n",
      "Targeting Medicaid enrollment for TN with target 1268904k\n",
      "Targeting Medicaid enrollment for TX with target 3821806k\n",
      "Targeting Medicaid enrollment for UT with target 300742k\n",
      "Targeting Medicaid enrollment for VA with target 1596777k\n",
      "Targeting Medicaid enrollment for VT with target 151833k\n",
      "Targeting Medicaid enrollment for WA with target 1776116k\n",
      "Targeting Medicaid enrollment for WI with target 1108320k\n",
      "Targeting Medicaid enrollment for WV with target 467632k\n",
      "Targeting Medicaid enrollment for WY with target 57320k\n"
     ]
    }
   ],
   "source": [
    "## SMALL CHECKS BELOW -- IGNORE ---\n",
    "\n",
    "## For approaches external to the reweighting approach implemented in enhanced CPS dataset creation\n",
    "\n",
    "files = [\n",
    "        STORAGE_FOLDER / \"enhanced_cps_2024.h5\",\n",
    "    ]\n",
    "\n",
    "minimization_function = random_sampling_minimization\n",
    "# other minimization function approach is \"random_sampling_minimization\", for which you can specify the tolerance for loss relative change.\n",
    "\n",
    "for file in files:\n",
    "    output_path = STORAGE_FOLDER / \"random_sampling_minimization\" / f\"{1.0}_enhanced_cps_2024_random_sampling_minimization_minimised.h5\"\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    minimise_dataset(\n",
    "        file,\n",
    "        output_path,\n",
    "        minimization_function=minimization_function, \n",
    "        target_fractions=[1.0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf8e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:24<00:00,  2.98it/s, loss=3.37e-5, loss_rel_change=-0.92] \n"
     ]
    }
   ],
   "source": [
    "input_dataset = ExtendedCPS_2024\n",
    "\n",
    "sim = Microsimulation(dataset=input_dataset)\n",
    "data = sim.dataset.load_dataset()\n",
    "data[\"household_weight\"] = {}\n",
    "original_weights = sim.calculate(\"household_weight\")\n",
    "original_weights = original_weights.values + np.random.normal(\n",
    "    1, 0.1, len(original_weights)\n",
    ")\n",
    "for year in range(2024, 2025):\n",
    "    loss_matrix, targets_array = build_loss_matrix(\n",
    "        input_dataset, year\n",
    "    )\n",
    "\n",
    "    bad_mask = loss_matrix.columns.isin(bad_targets)\n",
    "    keep_mask_bool = ~bad_mask\n",
    "    keep_idx = np.where(keep_mask_bool)[0]\n",
    "    loss_matrix_clean = loss_matrix.iloc[:, keep_idx]\n",
    "    targets_array_clean = targets_array[keep_idx]\n",
    "    assert loss_matrix_clean.shape[1] == targets_array_clean.size\n",
    "    assert loss_matrix_clean.shape[1] != loss_matrix.shape[1]\n",
    "\n",
    "    optimised_weights = reweight(\n",
    "        original_weights,\n",
    "        loss_matrix_clean,\n",
    "        targets_array_clean,\n",
    "        log_path=\"baseline_calibration_log.csv\",\n",
    "        epochs=250,  # Reduced epochs for faster processing\n",
    "    )\n",
    "    data[\"household_weight\"][year] = optimised_weights\n",
    "\n",
    "output_path = STORAGE_FOLDER / \"baseline\" / \"enhanced_cps_2024_baseline.h5\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save to HDF5 file\n",
    "with h5py.File(output_path, \"w\") as f:\n",
    "    for variable, values in data.items():\n",
    "        for year, value in values.items():\n",
    "            f.create_dataset(f\"{variable}/{year}\", data=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0fe2e",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "225debd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>parameter</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>41310</td>\n",
       "      <td>0.0069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  strategy parameter  dataset_size  total_loss\n",
       "0     none      none         41310      0.0069"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating dataframe to store regularization results\n",
    "\"\"\"\n",
    "\n",
    "# Initial dataframe setup\n",
    "reg_results_df = pd.DataFrame({\n",
    "    'strategy': ['none'],\n",
    "    'parameter': ['none'],\n",
    "    'dataset_size': [41310],\n",
    "    'total_loss': [6.9e-3]\n",
    "})\n",
    "\n",
    "def add_result(df, strategy, parameter, dataset_size, total_loss):\n",
    "    new_rows = pd.DataFrame({\n",
    "        'strategy': strategy,        \n",
    "        'parameter': parameter,      \n",
    "        'dataset_size': dataset_size,\n",
    "        'total_loss': total_loss\n",
    "    })\n",
    "    return pd.concat([reg_results_df, new_rows], ignore_index=True)\n",
    "\n",
    "# Example usage\n",
    "#reg_results_df = add_result(reg_results_df, ['L1', 'L2'], ['0.001','0.002'], [35000, 4000], [7.2e-3, 7.2e-3])\n",
    "reg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bb3ef3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>parameter</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>41310</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l0_exp</td>\n",
       "      <td>0.01</td>\n",
       "      <td>41310</td>\n",
       "      <td>1263.410322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l0_exp</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41310</td>\n",
       "      <td>1263.410322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l0_exp</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41310</td>\n",
       "      <td>1263.410322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>41310</td>\n",
       "      <td>1263.410322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41310</td>\n",
       "      <td>1263.410322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>41310</td>\n",
       "      <td>1263.410322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  strategy parameter  dataset_size   total_loss\n",
       "0     none      none         41310     0.006900\n",
       "1   l0_exp      0.01         41310  1263.410322\n",
       "2   l0_exp       0.1         41310  1263.410322\n",
       "3   l0_exp       0.1         41310  1263.410322\n",
       "4       l1      0.01         41310  1263.410322\n",
       "5       l1       0.1         41310  1263.410322\n",
       "6       l1       0.1         41310  1263.410322"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pulling values from created calibration_log.csv and .h5 files to populate the line plot dataframe\n",
    "\n",
    "( I need to pull the strategy (folder name), parameter (from file title??), dataset size (from length of .h5 file), and total loss (from sum of loss column in calibration_log_file.csv))\n",
    "\"\"\"\n",
    "\n",
    "approaches = [\"l0_exp\", \"l1\"] \n",
    "penalty_weights = [1e-2, 1e-1]\n",
    "\n",
    "def get_output_path(approach, file_name):\n",
    "    output_path = STORAGE_FOLDER / approach / file_name\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    return output_path\n",
    "\n",
    "for approach in approaches:\n",
    "    total_size = []\n",
    "    total_loss = []\n",
    "    for penalty_weight in penalty_weights:\n",
    "        strategy = approach\n",
    "        parameter = penalty_weight\n",
    "\n",
    "        # Pull length of .h5 file\n",
    "        h5_name = f\"enhanced_cps_2024_{strategy}_{parameter}_minimised.h5\"\n",
    "        h5_path = get_output_path(strategy, h5_name)\n",
    "        # see if this works\n",
    "        dataset_size = len(h5py.File(h5_path, \"r\")['household_weight/2024'])\n",
    "        total_size.append(dataset_size)\n",
    "\n",
    "        # Pull sum of loss column\n",
    "        cal_log_name = f\"calibration_log_{approach}_{penalty_weight}.csv\"\n",
    "        cal_log_path = get_output_path(approach, cal_log_name)\n",
    "        loss_sum = pd.read_csv(cal_log_path)['loss'].sum()\n",
    "        total_loss.append(loss_sum)\n",
    "\n",
    "        reg_results_df = add_result(reg_results_df, strategy, parameter, total_size, total_loss)\n",
    "        # does this weird recursion work?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "fraction = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "for fraction in fraction:\n",
    "    strategy = \"random_sampling_minimization\"\n",
    "    parameter = fraction\n",
    "\n",
    "    # Pull length of .h5 file\n",
    "    h5_name = f\"{fraction}_enhanced_cps_2024_random_sampling_minimization_minimised.h5\"\n",
    "    h5_path = STORAGE_FOLDER / strategy / h5_name\n",
    "    dataset_size = len(h5py.File(h5_path, \"r\")['household_weight/2024'])\n",
    "\n",
    "    # Pull sum of loss column\n",
    "    cal_log_name = f\"{fraction}_enhanced_cps_2024_random_sampling_minimization_minimised_calibration_log.csv\"\n",
    "    cal_log_path = STORAGE_FOLDER / strategy / cal_log_name\n",
    "    total_loss = pd.read_csv(cal_log_path)['loss'].sum()\n",
    "\n",
    "    add_result(df, strategy, parameter, dataset_size, total_loss)\n",
    "\n",
    "'''\n",
    "reg_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b203ccd",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policyengine-us-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
